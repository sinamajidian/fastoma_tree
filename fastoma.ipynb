{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0927039",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python3\n",
    "\n",
    "import numpy as np\n",
    "from sys import argv\n",
    "import pyoma.browser.db as db\n",
    "import pyoma.browser.models as mod\n",
    "import zoo.wrappers.aligners.mafft as mafft\n",
    "import zoo.wrappers.treebuilders.fasttree as fasttree\n",
    "from Bio import SeqIO\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio import AlignIO\n",
    "from Bio.Align import MultipleSeqAlignment\n",
    "from Bio.Alphabet import IUPAC, SingleLetterAlphabet\n",
    "from Bio.Seq import Seq, UnknownSeq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from collections import defaultdict\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "\n",
    "#  for development \n",
    "import matplotlib.pyplot as plt\n",
    "#import matplotlib\n",
    "#matplotlib.use('Agg')\n",
    "\n",
    "oma_database_address = \"/work/FAC/FBM/DBC/cdessim2/default/smajidi1/fastoma/archive/OmaServer.h5\"\n",
    "project_folder = \"/work/FAC/FBM/DBC/cdessim2/default/smajidi1/fastoma/v2d/folder/\"\n",
    "\n",
    "\n",
    "# PANPA.fa  PANPA.hogmap\n",
    "# The species name of query is the name of the file; \n",
    "#  argv[2] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fffe826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PANPA 2\n",
      "HUMAN 2\n"
     ]
    }
   ],
   "source": [
    "############### Parsing query proteome of species #######\n",
    "#########################################################\n",
    "\n",
    "project_files = listdir(project_folder)\n",
    "\n",
    "query_species_names = []\n",
    "for file in project_files:\n",
    "    if file.split(\".\")[-1]==\"fa\":\n",
    "        file_name_split = file.split(\".\")[:-1]\n",
    "        query_species_names.append('.'.join(file_name_split))\n",
    "\n",
    "# we may assert existence of query_species_name+\".fa/hogmap\"\n",
    "\n",
    "query_prot_records_species = [ ]\n",
    "for query_species_name in query_species_names:\n",
    "    query_prot_address = project_folder + query_species_name + \".fa\" \n",
    "    query_prot_records = list(SeqIO.parse(query_prot_address, \"fasta\")) \n",
    "    query_prot_records_species.append(query_prot_records)\n",
    "    \n",
    "# for development\n",
    "query_species_num = len(query_species_names)\n",
    "for species_i in range(query_species_num):\n",
    "    len_prot_record_i = len( query_prot_records_species[species_i] )\n",
    "    species_name_i = query_species_names[species_i]\n",
    "    print(species_name_i,len_prot_record_i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2543c820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of proteins in omamer output for  PANPA is 2\n",
      "number of proteins in omamer output for  HUMAN is 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([['HOG:A0566827.3b', 'HOG:A0505678.2b'],\n",
       "  ['HOG:A0562417.8d.65b', 'HOG:A0563565.5a.6a.2b']],\n",
       " [['PANPA37307', 'PANPA00008'], ['HUMAN00001', 'HUMAN48905']])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################### Parsing omamer's output  ########\n",
    "#####################################################\n",
    "\n",
    "query_prot_names_species = []\n",
    "query_hogids_species = []\n",
    "\n",
    "for query_species_name in query_species_names:\n",
    "    omamer_output_address = project_folder + query_species_name + \".hogmap\"     \n",
    "    omamer_output_file = open(omamer_output_address,'r');\n",
    "\n",
    "    query_prot_names= []\n",
    "    query_hogids= []\n",
    "\n",
    "    for line in omamer_output_file:\n",
    "        line_strip=line.strip()\n",
    "        if not line_strip.startswith('qs'):\n",
    "            line_split= line_strip.split(\"\\t\")        \n",
    "            query_prot_names.append(line_split[0])\n",
    "            query_hogids.append(line_split[1])\n",
    "    print(\"number of proteins in omamer output for \",query_species_name,\"is\",len(query_hogids)) # ,query_hogids\n",
    "    query_prot_names_species.append(query_prot_names)\n",
    "    query_hogids_species.append(query_hogids)\n",
    "    \n",
    "query_hogids_species, query_prot_names_species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82119e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PANPA\n",
      "Number of prot queries after filtering is 2\n",
      "HUMAN\n",
      "Number of prot queries after filtering is 2\n"
     ]
    }
   ],
   "source": [
    "###### Extracting unique HOG list and corresponding query proteins ########\n",
    "###########################################################################\n",
    "\n",
    "query_hogids_filtr_species = []\n",
    "query_prot_names_filtr_species = []\n",
    "query_prot_records_filtr_species = []\n",
    "\n",
    "for species_i in range(query_species_num):\n",
    "    print(query_species_names[species_i])\n",
    "    query_hogids =  query_hogids_species[species_i]\n",
    "    query_prot_names = query_prot_names_species[species_i]\n",
    "    \n",
    "    \n",
    "    query_hogids_root = [query_hogid.split(\".\")[0][4:]  for query_hogid in  query_hogids ]\n",
    "    query_hogids_root_uniqset = set(query_hogids_root)\n",
    "    query_hogids_root_np =  np.array(query_hogids_root)\n",
    "\n",
    "    uniq_indices= []\n",
    "    for hogid_root  in query_hogids_root_uniqset:\n",
    "\n",
    "        if  sum(query_hogids_root_np==hogid_root) == 1:  # not reptead\n",
    "\n",
    "            uniq_indx = query_hogids_root.index(hogid_root)\n",
    "            uniq_indices.append(uniq_indx)\n",
    "\n",
    "    query_hogids_filtr     = [query_hogids[i] for i in uniq_indices]\n",
    "    query_prot_names_filtr    = [query_prot_names[i] for i in uniq_indices]\n",
    "    query_prot_records_filtr  = [query_prot_records[i] for i in uniq_indices]\n",
    "\n",
    "    query_hogids_filtr_species.append(query_hogids_filtr)\n",
    "    query_prot_names_filtr_species.append(query_prot_names_filtr)\n",
    "    query_prot_records_filtr_species.append(query_prot_records_filtr)\n",
    "\n",
    "    \n",
    "    num_query_filtr = len(query_hogids_filtr)\n",
    "    print(\"Number of prot queries after filtering is\",num_query_filtr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b2f2d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05f2e8cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/FAC/FBM/DBC/cdessim2/default/smajidi1/software/miniconda3/lib/python3.8/site-packages/tables/leaf.py:402: PerformanceWarning: The Leaf ``/Protein/_i_Entries/OmaHOG/sorted`` is exceeding the maximum recommended rowsize (104857600 bytes);\n",
      "be ready to see PyTables asking for *lots* of memory and possibly slow\n",
      "I/O.  You may want to reduce the rowsize by trimming the value of\n",
      "dimensions that are orthogonal (and preferably close) to the *main*\n",
      "dimension of this leave.  Alternatively, in case you have specified a\n",
      "very small/large chunksize, you may want to increase/decrease it.\n",
      "  warnings.warn(\"\"\"\\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OMA data is parsed and its release name is : All.Apr2021\n",
      "PANPA\n",
      "For query PANPA00008\n",
      "the most Frequent_OG is: 942166 with frequency of 45 out of 48 so, frq= 0.9375 \n",
      "\n",
      "For query PANPA37307\n",
      "the most Frequent_OG is: 699878 with frequency of 164 out of 204 so, frq= 0.803921568627451 \n",
      "\n",
      "HUMAN\n",
      "For query HUMAN48905\n",
      "the most Frequent_OG is: 1016299 with frequency of 158 out of 207 so, frq= 0.7632850241545893 \n",
      "\n",
      "For query HUMAN00001\n",
      "the most Frequent_OG is: 604910 with frequency of 6 out of 12 so, frq= 0.5 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "############ Extracting the most frequent OG  ########\n",
    "#####################################################\n",
    "\n",
    "oma_db = db.Database(oma_database_address)\n",
    "print(\"OMA data is parsed and its release name is :\", oma_db.get_release_name())\n",
    "\n",
    "mostFrequent_OG_list_species = []\n",
    "OGs_correspond_proteins_num_list_species = []\n",
    "frq_most_frequent_og_list_species = []\n",
    "\n",
    "\n",
    "for species_i in range(query_species_num):\n",
    "    print(query_species_names[species_i])\n",
    "    query_hogids_filtr = query_hogids_filtr_species[species_i]\n",
    "    query_prot_names_filtr = query_prot_names_filtr_species[species_i]\n",
    "    query_prot_records_filtr = query_prot_records_filtr_species[species_i]\n",
    "    \n",
    "    mostFrequent_OG_list=[]\n",
    "    OGs_correspond_proteins_num_list = []\n",
    "    frq_most_frequent_og_list = []\n",
    "\n",
    "    for  item_idx in range(num_query_filtr):\n",
    "\n",
    "        hog_id= query_hogids_filtr[item_idx]\n",
    "\n",
    "        hog_members = oma_db.member_of_hog_id(hog_id, level = None)                # members of the input hog_id as objects\n",
    "        proteins_id_hog = [hog_member[0] for hog_member in hog_members]              # the protein IDs of hog members\n",
    "        proteins_object_hog = [db.ProteinEntry(oma_db, pr) for pr in proteins_id_hog]  # the protein IDs of hog members\n",
    "        OGs_correspond_proteins = [pr.oma_group for pr in proteins_object_hog]\n",
    "\n",
    "        OGs_correspond_proteins_fltr= [val_og  for val_og in OGs_correspond_proteins if val_og!=0] # removing OG of 0\n",
    "        OGs_correspond_proteins_num = len(OGs_correspond_proteins_fltr)\n",
    "        if OGs_correspond_proteins_num >0:\n",
    "            mostFrequent_OG = max(set(OGs_correspond_proteins_fltr), key = OGs_correspond_proteins_fltr.count)\n",
    "            mostFrequent_OG_list.append(mostFrequent_OG)\n",
    "\n",
    "            query_protein= query_prot_names_filtr[item_idx]\n",
    "\n",
    "\n",
    "            # for development\n",
    "            frq_most_frequent_og = OGs_correspond_proteins_fltr.count(mostFrequent_OG)/OGs_correspond_proteins_num \n",
    "            print(\"For query\",query_protein )\n",
    "            print(\"the most Frequent_OG is:\",mostFrequent_OG, \"with frequency of\",OGs_correspond_proteins_fltr.count(mostFrequent_OG),\n",
    "                  \"out of\", OGs_correspond_proteins_num,\"so, frq=\",frq_most_frequent_og,\"\\n\")\n",
    "            OGs_correspond_proteins_num_list.append(OGs_correspond_proteins_num)\n",
    "            frq_most_frequent_og_list.append(frq_most_frequent_og)\n",
    "\n",
    "        else: # empty OGs_correspond_proteins_fltr\n",
    "            mostFrequent_OG_list.append(-1)\n",
    "\n",
    "    mostFrequent_OG_list_species.append(mostFrequent_OG_list)\n",
    "    OGs_correspond_proteins_num_list_species.append(OGs_correspond_proteins_num_list)\n",
    "    frq_most_frequent_og_list_species.append(frq_most_frequent_og_list)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d4bc72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for development\n",
    "\n",
    "# plt.hist(frq_most_frequent_og_list) # , bins=10\n",
    "# #plt.show()\n",
    "# plt.savefig(query_protein_address+\"frq_most_frequent_og_list.png\")\n",
    "\n",
    "# plt.hist(OGs_correspond_proteins_num_list) # , bins=10\n",
    "# #plt.show()\n",
    "# plt.savefig(query_protein_address+\"OGs_correspond_proteins_num_list.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d053922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PANPA\n",
      "For query index 0 name HUMAN48905\n",
      "For query index 1 name HUMAN00001\n",
      "HUMAN\n",
      "For query index 0 name HUMAN48905\n",
      "For query index 1 name HUMAN00001\n",
      "number of OGs 2\n"
     ]
    }
   ],
   "source": [
    "########## Combine proteins of OG with queries ##################\n",
    "#################################################################\n",
    "\n",
    "seqRecords_all_species = []\n",
    "for species_i in range(query_species_num):\n",
    "    query_species_name = query_species_names[species_i]\n",
    "    print(query_species_name)\n",
    "    \n",
    "\n",
    "    seqRecords_OG_num_list = []\n",
    "\n",
    "    seqRecords_all = []\n",
    "    for  item_idx in range(num_query_filtr):\n",
    "        mostFrequent_OG = mostFrequent_OG_list[item_idx]\n",
    "        if mostFrequent_OG != -1:\n",
    "            OG_members = oma_db.oma_group_members(mostFrequent_OG)\n",
    "            proteins_object_OG = [db.ProteinEntry(oma_db, pr) for pr in OG_members]  # the protein IDs of og members\n",
    "             # covnert to biopython objects\n",
    "            seqRecords_OG=[SeqRecord(Seq(pr.sequence),str(pr.genome.uniprot_species_code),'','') for pr in proteins_object_OG]\n",
    "\n",
    "            query_protein= query_prot_names_filtr[item_idx]    \n",
    "            print(\"For query index\",item_idx,\"name\",query_protein)\n",
    "            seqRecords_query =  query_prot_records_filtr[item_idx] \n",
    "\n",
    "            seqRecords_query_edited = SeqRecord(Seq(str(seqRecords_query.seq)), query_species_name, '', '')\n",
    "            seqRecords =seqRecords_OG + [seqRecords_query_edited]\n",
    "            seqRecords_all.append(seqRecords)\n",
    "\n",
    "            # for development\n",
    "            #seqRecords_OG_num= len(seqRecords_OG)\n",
    "            #print(\"length of OG\",mostFrequent_OG,\"was\",seqRecords_OG_num,\",now is\",len(seqRecords),\"\\n\")\n",
    "            #seqRecords_OG_num_list.append(seqRecords_OG_num)\n",
    "            \n",
    "    seqRecords_all_species.append(seqRecords_all)\n",
    "        \n",
    "print(\"number of OGs\",len(seqRecords_all))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a690c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for development\n",
    "\n",
    "# plt.hist(seqRecords_OG_num_list) # , bins=10\n",
    "# #plt.show()\n",
    "# plt.savefig(query_protein_address+\"seqRecords_OG_num_list.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74ac091f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PANPA\n",
      "time elapsed for multiple sequence alignment:  3.286231756210327\n",
      "time elapsed for multiple sequence alignment:  0.8543035984039307\n",
      "HUMAN\n",
      "time elapsed for multiple sequence alignment:  3.2906973361968994\n",
      "time elapsed for multiple sequence alignment:  0.8512635231018066\n"
     ]
    }
   ],
   "source": [
    "############## MSA  ##############\n",
    "##################################\n",
    "\n",
    "\n",
    "result_maf2_all_species = []\n",
    "for species_i in range(query_species_num):\n",
    "    query_species_name = query_species_names[species_i]\n",
    "    print(query_species_name)\n",
    "    \n",
    "    seqRecords_all = seqRecords_all_species[species_i]\n",
    "    \n",
    "\n",
    "    #result_maf2_all=[]\n",
    "    for  item_idx in range(len(seqRecords_all)): #range(num_query_filtr):\n",
    "        seqRecords=seqRecords_all[item_idx]\n",
    "\n",
    "        wrapper_maf = mafft.Mafft(seqRecords,datatype=\"PROTEIN\")\n",
    "        result_maf1 = wrapper_maf()\n",
    "        time_taken_maf = wrapper_maf.elapsed_time  # \n",
    "        print(\"time elapsed for multiple sequence alignment: \",time_taken_maf)\n",
    "\n",
    "        result_maf2 = wrapper_maf.result\n",
    "        #result_maf2_all.append(result_maf2)\n",
    "        result_maf2_all_species.append(result_maf2)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "478b165e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211\n"
     ]
    }
   ],
   "source": [
    "############## Concatante alignments  ##############\n",
    "####################################################\n",
    "\n",
    "#alignments= result_maf2_all\n",
    "\n",
    "alignments= result_maf2_all_species\n",
    "\n",
    "all_labels = set(seq.id for aln in alignments for seq in aln)\n",
    "print(len(all_labels))\n",
    "\n",
    "# Make a dictionary to store info as we go along\n",
    "# (defaultdict is convenient -- asking for a missing key gives back an empty list)\n",
    "concat_buf = defaultdict(list)\n",
    "\n",
    "# Assume all alignments have same alphabet\n",
    "alphabet = alignments[0]._alphabet\n",
    "\n",
    "for aln in alignments:\n",
    "    length = aln.get_alignment_length()\n",
    "    # check if any labels are missing in the current alignment\n",
    "    these_labels = set(rec.id for rec in aln)\n",
    "    missing = all_labels - these_labels\n",
    "\n",
    "    # if any are missing, create unknown data of the right length,\n",
    "    # stuff the string representation into the concat_buf dict\n",
    "    for label in missing:\n",
    "        new_seq = UnknownSeq(length, alphabet=alphabet)\n",
    "        concat_buf[label].append(str(new_seq))\n",
    "\n",
    "    # else stuff the string representation into the concat_buf dict\n",
    "    for rec in aln:\n",
    "        concat_buf[rec.id].append(str(rec.seq))\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3ddf3f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GOSAR 1938 1938\n",
      "GOSHI 1938 1938\n",
      "SOYBN 1938 1938\n",
      "GOSRA 1938 1938\n",
      "PONAB 1938 1938\n",
      "ACTCC 1938 1938\n",
      "PHAAN 1938 1938\n",
      "CAPAN 1938 1938\n",
      "PHAVU 1938 1938\n",
      "GUITH 1938 1938\n",
      "GUITC 1938 1938\n",
      "BODSA 1938 1938\n",
      "LEIDB 1938 1938\n",
      "LEIIN 1938 1938\n",
      "LEIMA 1938 1938\n",
      "LEIMU 1938 1938\n",
      "LEPSE 1938 1938\n",
      "TRYCI 1938 1938\n",
      "TRYCC 1938 1938\n",
      "NAEGR 1938 1938\n",
      "EMIHU 1938 1938\n",
      "GIAIB 1938 1938\n",
      "GIAIC 1938 1938\n",
      "GIAIA 1938 1938\n",
      "TRIVA 1938 1938\n",
      "MONBE 1938 1938\n",
      "SALR5 1938 1938\n",
      "BATDE 1938 1938\n",
      "BATDJ 1938 1938\n",
      "SPIPN 1938 1938\n",
      "GONPJ 1938 1938\n",
      "PIRSE 1938 1938\n",
      "BRAFL 1938 1938\n",
      "BRALA 1938 1938\n",
      "PETMA 1938 1938\n",
      "EPTBU 1938 1938\n",
      "LEPOC 1938 1938\n",
      "ANGAN 1938 1938\n",
      "ANATE 1938 1938\n",
      "SERDU 1938 1938\n",
      "CYNSE 1938 1938\n",
      "GASAC 1938 1938\n",
      "ORYLA 1938 1938\n",
      "ORYME 1938 1938\n",
      "NOTFU 1938 1938\n",
      "POEFO 1938 1938\n",
      "POERE 1938 1938\n",
      "XIPMA 1938 1938\n",
      "ASTCA 1938 1938\n",
      "HAPBU 1938 1938\n",
      "NEOBR 1938 1938\n",
      "ORENI 1938 1938\n",
      "AMPOC 1938 1938\n",
      "AMPPE 1938 1938\n",
      "HIPCM 1938 1938\n",
      "ESOLU 1938 1938\n",
      "ASTMX 1938 1938\n",
      "PYGNA 1938 1938\n",
      "ICTPU 1938 1938\n",
      "DANRE 1938 1938\n",
      "LATCH 1938 1938\n",
      "PROCA 1938 1938\n",
      "LOXAF 1938 1938\n",
      "ECHTE 1938 1938\n",
      "RABIT 1938 1938\n",
      "OCHPR 1938 1938\n",
      "FUKDA 1938 1938\n",
      "HETGA 1938 1938\n",
      "CAVPO 1938 1938\n",
      "CHILA 1938 1938\n",
      "OCTDE 1938 1938\n",
      "JACJA 1938 1938\n",
      "CRIGR 1938 1938\n",
      "MOUSE 1938 1938\n",
      "RATNO 1938 1938\n",
      "NANGA 1938 1938\n",
      "ICTTR 1938 1938\n",
      "CERAT 1938 1938\n",
      "CHLSB 1938 1938\n",
      "MACFA 1938 1938\n",
      "MACMU 1938 1938\n",
      "MACNE 1938 1938\n",
      "MANLE 1938 1938\n",
      "PAPAN 1938 1938\n",
      "COLAP 1938 1938\n",
      "RHIBE 1938 1938\n",
      "RHIRO 1938 1938\n",
      "GORGO 1938 1938\n",
      "HUMAN 2907 2907\n",
      "PANPA 2907 2907\n",
      "PANTR 1938 1938\n",
      "NOMLE 1938 1938\n",
      "AOTNA 1938 1938\n",
      "CALJA 1938 1938\n",
      "SAIBB 1938 1938\n",
      "CARSF 1938 1938\n",
      "PROCO 1938 1938\n",
      "OTOGA 1938 1938\n",
      "BOVIN 1938 1938\n",
      "CAPHI 1938 1938\n",
      "SHEEP 1938 1938\n",
      "PIGXX 1938 1938\n",
      "TURTR 1938 1938\n",
      "VULVU 1938 1938\n",
      "MUSPF 1938 1938\n",
      "AILME 1938 1938\n",
      "URSAM 1938 1938\n",
      "URSMA 1938 1938\n",
      "FELCA 1938 1938\n",
      "PTEVA 1938 1938\n",
      "MYOLU 1938 1938\n",
      "ERIEU 1938 1938\n",
      "HORSE 1938 1938\n",
      "MANJA 1938 1938\n",
      "SARHA 1938 1938\n",
      "MONDO 1938 1938\n",
      "PHACI 1938 1938\n",
      "ANAPP 1938 1938\n",
      "FICAL 1938 1938\n",
      "JUNHY 1938 1938\n",
      "TAEGU 1938 1938\n",
      "MELUD 1938 1938\n",
      "CHRPI 1938 1938\n",
      "CHEAB 1938 1938\n",
      "PELSI 1938 1938\n",
      "SPHPU 1938 1938\n",
      "ANOCA 1938 1938\n",
      "XENTR 1938 1938\n",
      "XENLA 1938 1938\n",
      "CIOIN 1938 1938\n",
      "CIOSA 1938 1938\n",
      "ASTRU 1938 1938\n",
      "ACAPL 1938 1938\n",
      "STRPU 1938 1938\n",
      "DAPPU 1938 1938\n",
      "ORCCI 1938 1938\n",
      "FOLCA 1938 1938\n",
      "BOMMO 1938 1938\n",
      "DANPL 1938 1938\n",
      "DENPD 1938 1938\n",
      "TRICA 1938 1938\n",
      "MEGSC 1938 1938\n",
      "DROBS 1938 1938\n",
      "DROGR 1938 1938\n",
      "DROAN 1938 1938\n",
      "DROBP 1938 1938\n",
      "DROEL 1938 1938\n",
      "DROEU 1938 1938\n",
      "DROFC 1938 1938\n",
      "DROER 1938 1938\n",
      "DROME 1938 1938\n",
      "DROSE 1938 1938\n",
      "DROSI 1938 1938\n",
      "DROYA 1938 1938\n",
      "DROKI 1938 1938\n",
      "DROBM 1938 1938\n",
      "DROSZ 1938 1938\n",
      "DROTK 1938 1938\n",
      "DROGU 1938 1938\n",
      "DROOB 1938 1938\n",
      "DROMI 1938 1938\n",
      "DROPE 1938 1938\n",
      "DROPS 1938 1938\n",
      "DROWI 1938 1938\n",
      "DROHY 1938 1938\n",
      "DROAR 1938 1938\n",
      "DROMO 1938 1938\n",
      "DRONA 1938 1938\n",
      "DRONM 1938 1938\n",
      "DROVI 1938 1938\n",
      "LUCCU 1938 1938\n",
      "CULSO 1938 1938\n",
      "ANOGA 1938 1938\n",
      "ANODA 1938 1938\n",
      "AEDAE 1938 1938\n",
      "CULQU 1938 1938\n",
      "APIME 1938 1938\n",
      "BOMIM 1938 1938\n",
      "LINHU 1938 1938\n",
      "OOCBI 1938 1938\n",
      "CAMFO 1938 1938\n",
      "ATTCE 1938 1938\n",
      "NASVI 1938 1938\n",
      "RHOPR 1938 1938\n",
      "PEDHC 1938 1938\n",
      "CAPTE 1938 1938\n",
      "CAPI1 1938 1938\n",
      "LINUN 1938 1938\n",
      "CRAGI 1938 1938\n",
      "LOTGI 1938 1938\n",
      "NEMVE 1938 1938\n",
      "MNELE 1938 1938\n",
      "TRIAD 1938 1938\n",
      "ICHMU 1938 1938\n",
      "ICHMG 1938 1938\n",
      "PLABS 1938 1938\n",
      "RETFI 1938 1938\n",
      "PHYNI 1938 1938\n",
      "PHYPR 1938 1938\n",
      "PHYPN 1938 1938\n",
      "PHYRM 1938 1938\n",
      "PHYSP 1938 1938\n",
      "AURAN 1938 1938\n",
      "MICCC 1938 1938\n",
      "MICPC 1938 1938\n",
      "CHLRE 1938 1938\n",
      "VOLCA 1938 1938\n",
      "KLEFL 1938 1938\n",
      "PHYPA 1938 1938\n",
      "MARPO 1938 1938\n",
      "SELML 1938 1938\n"
     ]
    }
   ],
   "source": [
    "for (label, seq_arr) in concat_buf.items():\n",
    "    \n",
    "    a=SeqRecord(Seq(''.join(seq_arr), alphabet=alphabet), id=label)\n",
    "    print(label,len(''.join(seq_arr)),len(a))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2c83d33",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Sequences must all be the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-4353a14cbb08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Stitch all the substrings together using join (most efficient way),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# and build the Biopython data structures Seq, SeqRecord and MultipleSeqAlignment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m msa = MultipleSeqAlignment(SeqRecord(Seq(''.join(seq_arr), alphabet=alphabet), id=label)\n\u001b[0m\u001b[1;32m      4\u001b[0m                             for (label, seq_arr) in concat_buf.items())\n",
      "\u001b[0;32m/work/FAC/FBM/DBC/cdessim2/default/smajidi1/software/miniconda3/lib/python3.8/site-packages/Bio/Align/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, records, alphabet, annotations, column_annotations)\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_records\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0malphabet\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                 \u001b[0;31m# No alphabet was given, take a consensus alphabet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/work/FAC/FBM/DBC/cdessim2/default/smajidi1/software/miniconda3/lib/python3.8/site-packages/Bio/Align/__init__.py\u001b[0m in \u001b[0;36mextend\u001b[0;34m(self, records)\u001b[0m\n\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mrec\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_append\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpected_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/work/FAC/FBM/DBC/cdessim2/default/smajidi1/software/miniconda3/lib/python3.8/site-packages/Bio/Align/__init__.py\u001b[0m in \u001b[0;36m_append\u001b[0;34m(self, record, expected_length)\u001b[0m\n\u001b[1;32m    606\u001b[0m             \u001b[0;31m# raise ValueError(\"New sequence is not of length %i\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m             \u001b[0;31m#                  % self.get_alignment_length())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Sequences must all be the same length\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m         \u001b[0;31m# Using not self.alphabet.contains(record.seq.alphabet) needs fixing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Sequences must all be the same length"
     ]
    }
   ],
   "source": [
    "# Stitch all the substrings together using join (most efficient way),\n",
    "# and build the Biopython data structures Seq, SeqRecord and MultipleSeqAlignment\n",
    "msa = MultipleSeqAlignment(SeqRecord(Seq(''.join(seq_arr), alphabet=alphabet), id=label)\n",
    "                            for (label, seq_arr) in concat_buf.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7a005a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e001ef48",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "out_name_msa=omamer_output_address+\"_msa_concatanated.txt\"\n",
    "handle_msa_fasta = open(out_name_msa,\"w\")\n",
    "SeqIO.write(msa, handle_msa_fasta,\"fasta\")\n",
    "handle_msa_fasta.close()\n",
    "    \n",
    "print(len(msa),msa.get_alignment_length())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64cb3a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "############## Tree inference  ###################\n",
    "##################################################\n",
    "\n",
    "wrapper_tree=fasttree.Fasttree(msa,datatype=\"PROTEIN\")\n",
    "result_tree1 = wrapper_tree()\n",
    "\n",
    "time_taken_tree = wrapper_tree.elapsed_time \n",
    "time_taken_tree\n",
    "\n",
    "result_tree2 = wrapper_tree.result\n",
    "tree_nwk=str(result_tree2[\"tree\"])\n",
    "print(len(tree_nwk))\n",
    "\n",
    "out_name_tree=omamer_output_address+\"_tree.txt\"\n",
    "file1 = open(out_name_tree,\"w\")\n",
    "file1.write(tree_nwk)\n",
    "file1.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbd75e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_nwk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e68749",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef485cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
