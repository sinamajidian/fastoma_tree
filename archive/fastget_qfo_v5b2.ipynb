{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdfefe91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python3\n",
    "    \n",
    "# IMPORTNAT  this code accept only .fa file as proteome\n",
    "\n",
    " \n",
    "def parse_oma_db(oma_database_address):\n",
    "    \n",
    "    ############### Parsing OMA db ####################\n",
    "    ###################################################\n",
    "\n",
    "    oma_db = db.Database(oma_database_address)\n",
    "\n",
    "    current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "    print(current_time, \"- OMA data is parsed and its release name is:\", oma_db.get_release_name())\n",
    "    list_oma_speices = [z.uniprot_species_code for z in oma_db.tax.genomes.values()] \n",
    "    current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "    print(current_time,\"- There are\",len(list_oma_speices),\"species in the OMA database.\")\n",
    "    \n",
    "    return (oma_db, list_oma_speices)\n",
    "\n",
    "\n",
    "def parse_proteome(list_oma_speices):\n",
    "    \n",
    "    ############### Parsing query proteome of species #######\n",
    "    #########################################################\n",
    "\n",
    "    \n",
    "    # IMPORTNAT  this code accept only .fa file as proteome\n",
    "    project_files = listdir(address_working_folder+\"/omamer_search/proteome/\")\n",
    "\n",
    "    query_species_names = []\n",
    "    for file in project_files:\n",
    "        if file.split(\".\")[-1] == \"fa\":\n",
    "            file_name_split = file.split(\".\")[:-1]\n",
    "            query_species_names.append('.'.join(file_name_split))\n",
    "        if file.split(\".\")[-1] == \"fasta\":\n",
    "            file_name_split = file.split(\".\")[:-1]\n",
    "            query_species_names.append('.'.join(file_name_split))\n",
    "\n",
    "    # we may assert existence of query_species_name+\".fa/hogmap\"\n",
    "    prots_record_allspecies = [ ]\n",
    "    for query_species_name in query_species_names:\n",
    "        prot_address = address_working_folder +\"omamer_search/proteome/\"+ query_species_name + \".fa\" \n",
    "        \n",
    "        prots_record = list(SeqIO.parse(prot_address, \"fasta\")) \n",
    "        prots_record_allspecies.append(prots_record)\n",
    "\n",
    "    query_species_num = len(query_species_names)    \n",
    "    current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "    print(current_time,\"- The are\",str(query_species_num),\"species in the proteome folder.\")\n",
    "\n",
    "    # for development\n",
    "    for species_i in range(query_species_num):\n",
    "        len_prot_record_i = len( prots_record_allspecies[species_i] )\n",
    "        species_name_i = query_species_names[species_i]\n",
    "        #print(species_name_i,len_prot_record_i)\n",
    "        if species_name_i in list_oma_speices: \n",
    "            current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "            print(current_time,\"- the species\",species_name_i,\" already exists in the oma database, remove them first\")\n",
    "            exit()\n",
    "\n",
    "      \n",
    "    # The proteins are parsed using  Bio.SeqIO.parse\n",
    "    # the first part of the header line before space \n",
    "    # >tr|A0A2I3FYY2|A0A2I3FYY2_NOMLE Uncharacterized protein OS=Nomascus leucogenys OX=61853 GN=CLPTM1L PE=3 SV=1\n",
    "    # will be \">tr|A0A2I3FYY2|A0A2I3FYY2_NOMLE\"\n",
    "    # [i.id for i in prots_record_allspecies[0] if len(i.id)!=30 and len(i.id)!=22 ] #'sp|O47892|CYB_NOMLE',\n",
    "    \n",
    "\n",
    "    \n",
    "    return (query_species_names, prots_record_allspecies)\n",
    "\n",
    "\n",
    "def parse_hogmap_omamer(query_species_names):\n",
    "\n",
    "    ################### Parsing omamer's output  ########\n",
    "    #####################################################\n",
    "    \n",
    "    prots_hogmap_name_allspecies = []\n",
    "    prots_hogmap_hogid_allspecies = []\n",
    "    prots_hogmap_subfscore_allspecies = []\n",
    "    prots_hogmap_seqlen_allspecies = []\n",
    "    prots_hogmap_subfmedseqlen_allspecies = []\n",
    "\n",
    "    for query_species_name in query_species_names:\n",
    "        omamer_output_address = address_working_folder + \"omamer_search/hogmap/\"+ query_species_name + \".hogmap\"     \n",
    "        omamer_output_file = open(omamer_output_address,'r');\n",
    "        prots_hogmap_name = []\n",
    "        prots_hogmap_hogid = []\n",
    "        prots_hogmap_subfscore = []\n",
    "        prots_hogmap_seqlen = []\n",
    "        prots_hogmap_subfmedseqlen = []\n",
    "        \n",
    "        for line in omamer_output_file:\n",
    "            line_strip=line.strip()\n",
    "            if not line_strip.startswith('qs'):\n",
    "                line_split= line_strip.split(\"\\t\")    \n",
    "                #if line_split[1]!='na':\n",
    "                prots_hogmap_name.append(line_split[0])\n",
    "                prots_hogmap_hogid.append(line_split[1])\n",
    "                prots_hogmap_subfscore.append(line_split[4]) # subfamily\n",
    "                prots_hogmap_seqlen.append(line_split[5])\n",
    "                prots_hogmap_subfmedseqlen.append(line_split[6])\n",
    "                \n",
    "        prots_hogmap_name_allspecies.append(prots_hogmap_name)\n",
    "        prots_hogmap_hogid_allspecies.append(prots_hogmap_hogid)\n",
    "        prots_hogmap_subfscore_allspecies.append(prots_hogmap_subfscore)\n",
    "        prots_hogmap_seqlen_allspecies.append(prots_hogmap_seqlen)\n",
    "        prots_hogmap_subfmedseqlen_allspecies.append(prots_hogmap_subfmedseqlen)\n",
    "    \n",
    "    current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "    print(current_time,\"- There are \",len(prots_hogmap_name_allspecies),\" species in the hogmap folder.\")\n",
    "    print(current_time,\"- The first species\",query_species_names[0],\" contains \",len(prots_hogmap_hogid_allspecies[0]),\" proteins.\")\n",
    "    print(current_time,\"- The first protein of first species is \", prots_hogmap_name_allspecies[0][0])\n",
    "\n",
    "    hogmap_allspecies = (prots_hogmap_name_allspecies, prots_hogmap_hogid_allspecies, prots_hogmap_subfscore_allspecies, prots_hogmap_seqlen_allspecies, prots_hogmap_subfmedseqlen_allspecies)\n",
    "    return  hogmap_allspecies\n",
    "    \n",
    "    \n",
    "    \n",
    "def filter_prot_mapped(query_species_names, query_prot_records_species,query_prot_names_species_mapped):\n",
    "    # omamer remove very small proteins, \n",
    "    # so  we lose track of order comparing hogmap and fasta file\n",
    "    # the goal here is to remove those from seq record (of the fasta file)\n",
    "    current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "    print(current_time,\"- Filtering proteins started.\")\n",
    "\n",
    "    query_prot_records_species_filtered=[]\n",
    "    for species_idx in range(len(query_species_names)):    \n",
    "        # from fasta file\n",
    "        query_species_name=query_species_names[species_idx]\n",
    "        print(query_species_name)\n",
    "        query_prot_records_species_i = query_prot_records_species[species_idx]\n",
    "        query_prot_ids_records = [record.id for record in query_prot_records_species_i]\n",
    "\n",
    "        # from hogmap file\n",
    "        # without proteins that are not mapped on any hogs\n",
    "        query_prot_names_species_i = query_prot_names_species_mapped[species_idx]\n",
    "\n",
    "        if len(query_prot_names_species_i) != len(query_prot_records_species_i):\n",
    "\n",
    "            query_prot_records_filterd=[]\n",
    "            for query_prot_name in query_prot_names_species_i:\n",
    "                if query_prot_name in query_prot_ids_records:\n",
    "                    prot_record_idx = query_prot_ids_records.index(query_prot_name)\n",
    "                    prot_record = query_prot_records_species_i[prot_record_idx]\n",
    "                    query_prot_records_filterd.append(prot_record)\n",
    "                else:\n",
    "                    current_time = datetime.now().strftime(\"%H:%M:%S\")                    \n",
    "                    print(current_time,\"- Error\",query_species_name, query_prot_name)\n",
    "\n",
    "            current_time = datetime.now().strftime(\"%H:%M:%S\")        \n",
    "            print(current_time,\"- For the species\", query_species_name, \", few proteins were ignored by omamer.\")\n",
    "            print(current_time,\"- before filtering: in hogmap\", len(query_prot_names_species_i), \"in proteome\", len(query_prot_records_species_i))\n",
    "            print(current_time,\"- After filtering:  in hogmap\", len(query_prot_names_species_i), \"in proteome\", len(query_prot_records_filterd))            \n",
    "            \n",
    "\n",
    "        else:\n",
    "            query_prot_records_filterd = query_prot_records_species_i\n",
    "\n",
    "        query_prot_records_species_filtered.append(query_prot_records_filterd)\n",
    "    current_time = datetime.now().strftime(\"%H:%M:%S\")        \n",
    "    print(current_time,\"- For the rest of species, all proteins were mapped using OMAmer.\")\n",
    "\n",
    "    return query_prot_records_species_filtered\n",
    "\n",
    "\n",
    "def run_one_msa(seqRecords_queries):\n",
    "    ############## MSA  ##############\n",
    "    ##################################\n",
    "    #current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "    #print(current_time, \"- working on new OG with length of \",len(seqRecords_OG_queries))\n",
    "    \n",
    "    \n",
    "    wrapper_mafft = mafft.Mafft(seqRecords_queries,datatype=\"PROTEIN\") \n",
    "    # MAfft error: Alphabet 'U' is unknown. -> add --anysymbol argument needed to define in the sourse code\n",
    "    # workaround sed \"s/U/X/g\"\n",
    "    \n",
    "    wrapper_mafft.options.options['--retree'].set_value(1)\n",
    "\n",
    "\n",
    "    run_mafft = wrapper_mafft() # it's wrapper  storing the result  and time \n",
    "    time_taken_mafft = wrapper_mafft.elapsed_time\n",
    "\n",
    "    result_mafft = wrapper_mafft.result \n",
    "    time_taken_mafft2 = wrapper_mafft.elapsed_time\n",
    "    \n",
    "    current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "    #print(current_time,\"- time elapsed for MSA: \",time_taken_mafft2)\n",
    "    #print(current_time,\"- MSA for an OG is just finished: \",time_taken_mafft2)\n",
    "\n",
    "    return(result_mafft)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def draw_tree(msa, tree_out_file):\n",
    "    ############## Tree inference  ###################\n",
    "    ##################################################\n",
    "\n",
    "    wrapper_tree=fasttree.Fasttree(msa,datatype=\"PROTEIN\")\n",
    "    wrapper_tree.options.options['-fastest']    \n",
    "    result_tree1 = wrapper_tree()\n",
    "\n",
    "    time_taken_tree = wrapper_tree.elapsed_time \n",
    "    time_taken_tree\n",
    "\n",
    "    result_tree2 = wrapper_tree.result\n",
    "    tree_nwk=str(result_tree2[\"tree\"])\n",
    "    current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "    #print(current_time,\"- \",len(tree_nwk))\n",
    "\n",
    "    if len(tree_out_file)>255: tree_out_file = tree_out_file[:255]\n",
    "    file1 = open(tree_out_file,\"w\")\n",
    "    file1.write(tree_nwk)\n",
    "    file1.write(\";\\n\")\n",
    "    file1.close() \n",
    "    return tree_nwk\n",
    "\n",
    "\n",
    "\n",
    "def merge_msa(list_msas):\n",
    "    \n",
    "    #logging.debug(list_msas)\n",
    "    #logging.debug(str(list_msas[0][0].seq)+\"\\n\")\n",
    "    #logging.debug(str(list_msas[0][0].id)+\"\\n\")\n",
    "    #logging.debug(str(list_msas[1][0].seq)+\"\\n\")\n",
    "    #logging.debug(str(list_msas[0][0].id)+\"\\n\")\n",
    "    \n",
    "    # each element of msa should be  a MultipleSeqAlignment\n",
    "    wrapper_mafft_merge = mafft.Mafft(list_msas, datatype=\"PROTEIN\") \n",
    "    wrapper_mafft_merge.options['--merge'].active = True\n",
    "    merged = wrapper_mafft_merge()\n",
    "    \n",
    "    \n",
    "    print(len(list_msas),\"msas are merged into one with the length of \",len(merged),len(merged[0]) )\n",
    "    return merged\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "# def compact_distance_matrix_tree(tree_input):\n",
    "\n",
    "#     # tree_input   in ete3 format\n",
    "#     # output  a vector upper triangulare \n",
    "    \n",
    "#     tree_leaves=[]\n",
    "#     for node in tree_input.traverse(strategy=\"postorder\"):\n",
    "#         if node.is_leaf() : \n",
    "#             node_name = node.name\n",
    "#             tree_leaves.append(node_name)\n",
    "\n",
    "\n",
    "#     leaves_num = len(tree_leaves)\n",
    "#     distance_matrix = np.zeros([leaves_num,leaves_num])\n",
    "\n",
    "#     for i in range(leaves_num):\n",
    "#         for j in range(leaves_num):\n",
    "#             if i < j:\n",
    "#                 value= round(tree_input.get_distance(tree_leaves[i],tree_leaves[j]),3)\n",
    "#                 distance_matrix[i][j]= value\n",
    "#                 distance_matrix[j][i]= value\n",
    "\n",
    "#     y=[]\n",
    "#     for i in range(len(distance_matrix)):\n",
    "#         for j in range(len(distance_matrix)):\n",
    "#             if i<j:\n",
    "#                 val= distance_matrix[i][j]\n",
    "#                 y.append(val)\n",
    "#     return (y,tree_leaves)\n",
    "\n",
    " \n",
    "    \n",
    "    \n",
    "def lable_SD_internal_nodes(tree_out):\n",
    "\n",
    "    species_name_dic={}\n",
    "    counter_S=0\n",
    "    counter_D=0\n",
    "    \n",
    "    for node in tree_out.traverse(strategy = \"postorder\"):\n",
    "        #print(\"** now working on node \",node.name) # node_children\n",
    "\n",
    "        if node.is_leaf() :\n",
    "            prot_i = node.name\n",
    "            species_name_dic[node] = { str(prot_i).split(\"|\")[-1].split(\"_\")[-1] }\n",
    "\n",
    "        else:\n",
    "            node.name= \"S/D\"\n",
    "            leaves_list = node.get_leaves()\n",
    "            #print(\"leaves_list\", leaves_list)\n",
    "            \n",
    "\n",
    "            species_name_set = set([ str(prot_i).split(\"|\")[-1].split(\"_\")[-1] for prot_i in leaves_list])\n",
    "            #print(\"species_name_set\", species_name_set)\n",
    "            species_name_dic[node] = species_name_set\n",
    "\n",
    "\n",
    "            node_children = node.children\n",
    "            #print(node_children)\n",
    "            node_children_species_list = [species_name_dic[node_child] for node_child in node_children] # list of sets\n",
    "            \n",
    "            #print(\"node_children_species_list\", node_children_species_list)\n",
    "            \n",
    "            node_children_species_intersection = set.intersection(*node_children_species_list)\n",
    "\n",
    "            if  node_children_species_intersection :\n",
    "                #print(\"node_children_species_list\",node_children_species_list)\n",
    "                counter_D += 1\n",
    "                node.name = \"D\"+str(counter_D)\n",
    "                \n",
    "            else:\n",
    "                counter_S += 1\n",
    "                node.name = \"S\"+str(counter_S)\n",
    "\n",
    "    return tree_out\n",
    "\n",
    "def add_species_name(query_prot_records_species,query_species_names):\n",
    "\n",
    "    for ix in range(len(query_species_names)):\n",
    "        query_species_name = query_species_names[ix]\n",
    "        query_prot_records = query_prot_records_species[ix]\n",
    "        for i_prot in range(len(query_prot_records)):\n",
    "            query_prot_record = query_prot_records[i_prot]\n",
    "            query_prot_record.description += \"|species|\"+query_species_name\n",
    "            \n",
    "    return query_prot_records_species\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def read_omaID_file(omaID_address):\n",
    "    \n",
    "    omaID_file = open(omaID_address,'r')\n",
    "\n",
    "    taxonID_omaID={}\n",
    "    omaID_taxonID={}\n",
    "\n",
    "    # omaID_scienceFull={}\n",
    "    # scienceFull_omaID={}\n",
    "    scientific_taxonID={}\n",
    "    taxonID_scientific={}\n",
    "\n",
    "    #  !!! limitation  ignoring strains and isolate\n",
    "    for line in omaID_file:\n",
    "        line_strip = line.strip()\n",
    "        if line_strip.startswith('#'):\n",
    "            pass\n",
    "            #header_lines_list.append(line_strip)\n",
    "        else:\n",
    "            line_parts = line_strip.split('\\t')\n",
    "\n",
    "            omaID = line_parts[0]\n",
    "            taxonID = line_parts[1]\n",
    "            taxonID_omaID[taxonID] = omaID\n",
    "            omaID_taxonID[omaID] = taxonID\n",
    "\n",
    "            scientific = line_parts[2]\n",
    "            taxonID_scientific[taxonID] = scientific\n",
    "            scientific_taxonID[scientific] = taxonID\n",
    "\n",
    "    omaID_file.close()\n",
    "\n",
    "    print(\"-- The map for OMA taxonID of\",len(taxonID_omaID),\"records have read.\") \n",
    "    \n",
    "    return (taxonID_omaID,omaID_taxonID,taxonID_scientific,scientific_taxonID)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def write_rootHOGs(prots_hogmap_hogid_allspecies, address_out_hog):\n",
    "\n",
    "    prots_hogmap_rhogid_allspecies = []\n",
    "    for prots_hogmap_hogid in prots_hogmap_hogid_allspecies:\n",
    "        prots_hogmap_rhogid = []\n",
    "        for prot_hogmap_hogid in prots_hogmap_hogid:\n",
    "            prot_hogmap_rhogid=prot_hogmap_hogid.split(\".\")[0]\n",
    "            prots_hogmap_rhogid.append(prot_hogmap_rhogid)\n",
    "\n",
    "        prots_hogmap_rhogid_allspecies.append(prots_hogmap_rhogid)\n",
    "\n",
    "\n",
    "    rhogid_prot_idx_dic = {}\n",
    "    for species_idx in range(len(query_species_names)):\n",
    "\n",
    "        species_name = query_species_names[species_idx]\n",
    "\n",
    "        prots_hogmap_rhogid = prots_hogmap_rhogid_allspecies[species_idx]\n",
    "\n",
    "        for prots_hogmap_idx in range(len(prots_hogmap_rhogid)):\n",
    "\n",
    "            prot_hogmap_rhogid = prots_hogmap_rhogid[prots_hogmap_idx]\n",
    "            if prot_hogmap_rhogid in rhogid_prot_idx_dic:\n",
    "                rhogid_prot_idx_dic[prot_hogmap_rhogid].append((species_idx, prots_hogmap_idx))\n",
    "            else:\n",
    "                rhogid_prot_idx_dic[prot_hogmap_rhogid] = [(species_idx, prots_hogmap_idx)]\n",
    "    print(len(rhogid_prot_idx_dic)) #  rhogid_prot_idx_dic['HOG:0018405']\n",
    "\n",
    "\n",
    "\n",
    "    rhogids_prot_records_query = [ ]\n",
    "    rhogids_list = []\n",
    "    for rhogid in rhogid_prot_idx_dic.keys() :\n",
    "        rhogid_prot_records = []\n",
    "        if rhogid != \"na\" and len(rhogid)>1:\n",
    "            rhogids_list.append(rhogid)\n",
    "            rhogid_prot_idx =  rhogid_prot_idx_dic[rhogid]\n",
    "            for (species_idx, prots_hogmap_idx) in rhogid_prot_idx:\n",
    "                prot_record = query_prot_records_species_filtered[species_idx][prots_hogmap_idx] \n",
    "                #print(prot_record)\n",
    "                rhogid_prot_records.append(prot_record)\n",
    "\n",
    "            rhogids_prot_records_query.append(rhogid_prot_records) \n",
    "        else:\n",
    "            print(\"root hog na / lenght of one \",rhogid)\n",
    "    print(len(rhogids_prot_records_query),len(rhogids_prot_records_query[0]))\n",
    "    \n",
    "    \n",
    "    #rhogids_prot_records = []\n",
    "    rhogid_num_list= []\n",
    "    for rhogid_idx in range(len(rhogids_list)):\n",
    "        #if rhogid_idx %500 ==0 : print(rhogid_idx)\n",
    "        rhogid_prot_records_query= rhogids_prot_records_query[rhogid_idx] \n",
    "\n",
    "        rhogid = rhogids_list[rhogid_idx]\n",
    "\n",
    "        rhogid_B= rhogid.split(\":\")[1]\n",
    "        rhogid_num= int(rhogid_B[1:] ) # # B0613860\n",
    "        rhogid_num_list.append(rhogid_num)\n",
    "        if  len(rhogid_prot_records_query) < 100  and len(rhogid_prot_records_query) > 2 :\n",
    "    #         rhogids_prot_records_oma = []\n",
    "    #         for hog_elements in oma_db.member_of_fam(rhogid_num):   # this gets the member of roothog 2 (HOG:000002)\n",
    "    #             prot_hog_element = ProteinEntry(oma_db, hog_elements)\n",
    "    #             #print(prot_hog_element.omaid, prot_hog_element.hog_family_nr, len(prot_hog_element.sequence),prot_hog_element.sequence[0])\n",
    "    #             rhogids_prot_records_oma.append(SeqRecord(Seq(prot_hog_element.sequence), id=prot_hog_element.omaid))\n",
    "    #         rhogids_prot_records_both= rhogids_prot_records_oma +  rhogid_prot_records_query\n",
    "    #         rhogids_prot_records.append(rhogids_prot_records_both)\n",
    "            SeqIO.write(rhogid_prot_records_query, address_out_hog+\"HOG_\"+str(rhogid_num)+\".fa\", \"fasta\")\n",
    "\n",
    "    print(\"all HOGs   (>2 <100) has written.\",len(rhogids_prot_records_query),len(rhogids_list), len(rhogid_prot_records_query), len(rhogid_prot_records_query[0]))\n",
    "\n",
    "    return (rhogid_num_list, rhogids_prot_records_query)\n",
    "    \n",
    "    \n",
    "def read_species_tree(tree_address):\n",
    "    print(tree_address)\n",
    "    #print(round(os.path.getsize(tree_address)/1000),\"kb\")\n",
    "\n",
    "    project = Phyloxml()\n",
    "    project.build_from_file(tree_address)\n",
    "    # Each tree contains the same methods as a PhyloTree object\n",
    "    for species_tree in project.get_phylogeny():\n",
    "        len(species_tree)\n",
    "        #print(species_tree)\n",
    "\n",
    "    for node_species_tree in species_tree.traverse(strategy = \"postorder\"):\n",
    "        if node_species_tree.is_leaf():\n",
    "            temp1 =node_species_tree.phyloxml_clade.get_taxonomy()[0]\n",
    "            #print(temp1.get_code())     \n",
    "            node_species_tree.name = temp1.get_code()\n",
    "    #print(len(species_tree))\n",
    "    #print(species_tree)\n",
    "    \n",
    "    return (species_tree)   \n",
    "    \n",
    "\n",
    "    \n",
    "def traverse_geneTree_assign_hog(gene_tree, merged_msa):\n",
    "    # gene_tree should be labeled with S/ D\n",
    "    tree_leaves = [ i.name for i in gene_tree.get_leaves()] \n",
    "    assigned_leaves_to_hog = []\n",
    "    sub_msas_list_this_level = []\n",
    "\n",
    "    for node in gene_tree.traverse(strategy = \"preorder\"): # start from root\n",
    "        #print(\"Leaves assigned to hog are \", assigned_leaves_to_hog)\n",
    "        #print(\"Traversing gene tree. Now at node\", node.name)\n",
    "\n",
    "        if node.is_root() and node.name[0] == \"S\":    \n",
    "            sub_msas_list_this_level = [merged_msa]\n",
    "            assigned_leaves_to_hog = tree_leaves\n",
    "            # we do not need to traverse the gene tree any more \n",
    "            break\n",
    "\n",
    "        if not node.is_leaf() : \n",
    "            node_leaves_name = [ i.name for i in node.get_leaves() ] \n",
    "            \n",
    "            # ?? ?? \n",
    "            if node_leaves_name[0] in assigned_leaves_to_hog:\n",
    "                # if one of them is there, since  preorder,  all should be there ???    \n",
    "                # the node are assigned to hogs, we are done. \n",
    "                # it is not needed to check the children of a speciecation\n",
    "                continue  # go to next node\n",
    "\n",
    "            if node.name[0] ==\"S\":\n",
    "                # this is a sub-hog.\n",
    "                assigned_leaves_to_hog += node_leaves_name\n",
    "                leaves_msa = [i.id for i in merged_msa]\n",
    "                idx_species_list = [leaves_msa.index(i) for i in node_leaves_name] \n",
    "                #print(\"idx_species_list\",idx_species_list)\n",
    "                #print(\"node_leaves_name\",node_leaves_name)\n",
    "                \n",
    "                sub_msa_seq_list = [  merged_msa[i]   for i in idx_species_list]  # sub_msas_list_lowerlevel \n",
    "                sub_msa = run_one_msa(sub_msa_seq_list)\n",
    "                sub_msas_list_this_level.append(sub_msa)\n",
    "\n",
    "                if  set(tree_leaves)==set(assigned_leaves_to_hog) :\n",
    "                    # all leaves are assigned to hogs, we are done. \n",
    "                    break\n",
    "\n",
    "        if node.is_leaf() and not node.name in assigned_leaves_to_hog:\n",
    "            #  singletone leaf, can be a hog. \n",
    "            assigned_leaves_to_hog.append(node.name)\n",
    "            #print(\"assigned_leaves_to_hog\",assigned_leaves_to_hog)\n",
    "            leaves_msa = [i.id for i in merged_msa]\n",
    "            #print(\"leaves_msa\",leaves_msa)\n",
    "\n",
    "            idx_species = leaves_msa.index(node.name)\n",
    "            sub_msa = MultipleSeqAlignment([merged_msa[idx_species]])\n",
    "            sub_msas_list_this_level.append(sub_msa)\n",
    "            \n",
    "    return (assigned_leaves_to_hog, sub_msas_list_this_level)\n",
    "            \n",
    "\n",
    "def prepare_species_tree(rhog_i, species_tree):\n",
    "\n",
    "    species_names_rhog= []\n",
    "    prot_names_rhog=[]\n",
    "    for rec in rhog_i:\n",
    "        prot_name= rec.name # # 'tr|E3JPS4|E3JPS4_PUCGT\n",
    "        #prot_name = prot_name_full.split(\"|\")[1].strip() # # 'tr|E3JPS4|E3JPS4_PUCGT\n",
    "        species_name = prot_name.split(\"|\")[-1].split(\"_\")[-1]\n",
    "        if species_name=='RAT': species_name=\"RATNO\"\n",
    "\n",
    "        species_names_rhog.append(species_name)\n",
    "        prot_names_rhog.append(prot_name)\n",
    "\n",
    "    species_names_uniqe = set(species_names_rhog)\n",
    "    print(\"number of unique species in the rHOG\", len(species_names_uniqe))\n",
    "\n",
    "    \n",
    "    species_tree.prune(species_names_uniqe, preserve_branch_length=True )\n",
    "    species_tree.write()\n",
    "\n",
    "    for node in species_tree.traverse(strategy = \"postorder\"):\n",
    "        node_name = node.name\n",
    "        if len(node_name) <1: \n",
    "            if node.is_leaf():\n",
    "                node.name = \"leaf_\"+str(num_leaves_no_name)\n",
    "            else:\n",
    "                node_children = node.children\n",
    "                list_children_names = [node_child.name for node_child in node_children]\n",
    "                node.name = '_'.join(list_children_names)\n",
    "\n",
    "    print(\"Working on the following species tree.\")\n",
    "    #print(species_tree)\n",
    "    \n",
    "    return (species_tree, species_names_rhog, prot_names_rhog)\n",
    "\n",
    "\n",
    "\n",
    "def find_paralog_thisLevel(tree_leaves, subHOG_thisLevel):\n",
    "    \n",
    "    paralog_set_thisLevel = set()\n",
    "    for i in range(len(tree_leaves)):\n",
    "        prot_i = tree_leaves[i]\n",
    "        species_i = prot_i.split(\"|\")[-1].split(\"_\")[-1]\n",
    "        for j in range(i+1):\n",
    "            prot_j = tree_leaves[j]\n",
    "            species_j = prot_j.split(\"|\")[-1].split(\"_\")[-1]\n",
    "            if species_i == species_j:\n",
    "                paralog_set_thisLevel.add((prot_i,prot_j))\n",
    "                paralog_set_thisLevel.add((prot_j,prot_i))\n",
    "\n",
    "    for i in range(len(subHOG_thisLevel)):\n",
    "        subHOG_i = subHOG_thisLevel[i]\n",
    "        for j in range(i):\n",
    "            subHOG_j = subHOG_thisLevel[j]\n",
    "            for i1 in range(len(subHOG_i)):\n",
    "                prot_i = subHOG_i[i1]\n",
    "                for j1 in range(len(subHOG_j)):\n",
    "                    prot_j = subHOG_j[j1]\n",
    "                    paralog_set_thisLevel.add((prot_i,prot_j))\n",
    "                    paralog_set_thisLevel.add((prot_j,prot_i))\n",
    " \n",
    "    return paralog_set_thisLevel\n",
    "\n",
    "\n",
    "\n",
    "def infer_HOG_thisLevel(node_species_tree, rhog_i, species_names_rhog, dic_sub_msas, rhogid_num):\n",
    "\n",
    "    sub_msa_list_lowerLevel = [] # including subHOGS of lower level \n",
    "    for node_child in node_species_tree.children:\n",
    "        if  node_child.is_leaf():\n",
    "            node_species_name = node_child.name\n",
    "            # for a extant species \n",
    "            # extracting prot sequeincg of the species from the rootHOG\n",
    "            interest_list = [idx  for idx in range(len(species_names_rhog)) if species_names_rhog[idx] == node_species_name ]\n",
    "            rhog_part = [rhog_i[i] for i in interest_list]\n",
    "            sub_msa = [MultipleSeqAlignment([i]) for i in rhog_part] \n",
    "        else:   # the child node is an internal node, subHOGs are inferred till now in traversing.\n",
    "            print(\"sub msa for internal node\", node_child.name,\"is read from dic.\")\n",
    "            if node_child.name in dic_sub_msas:\n",
    "                sub_msa  = dic_sub_msas[node_child.name]\n",
    "            else:\n",
    "                print(\"error 131, no sub msa for the internal node \",node_child.name, node_child)\n",
    "                assert 2==1 \n",
    "        sub_msa_list_lowerLevel += sub_msa\n",
    "\n",
    "\n",
    "    if len(sub_msa_list_lowerLevel) <2:\n",
    "        print(\"**** issue **  \", len(sub_msa_list_lowerLevel),sub_msa_list_lowerLevel)\n",
    "        return (-1,-1,-1)\n",
    "    \n",
    "    print(\"There are\",len(sub_msa_list_lowerLevel),\" subHOGs in the lower level.\")\n",
    "    #print(\"We want to infer subHOGs at this level,i.e. merge few of them.\")    \n",
    "    #time.sleep(1)     # shall I wait to have all  msa run finsihed? \n",
    "    \n",
    "    #all hog of child\n",
    "    #get msa\n",
    "    \n",
    "    merged_msa = merge_msa(sub_msa_list_lowerLevel) \n",
    "\n",
    "    print(\"All subHOGs are merged, merged msa is with length of\",len(merged_msa), len(merged_msa[0]),\".\")\n",
    "\n",
    "    gene_tree_file =  address_working_folder + \"/gene_trees_test/tree_\"+str(rhogid_num)+\"_\"+str(node_species_tree.name)+\".nwk\"\n",
    "    \n",
    "    gene_tree_raw = draw_tree(merged_msa, gene_tree_file)\n",
    "    gene_tree = Tree(gene_tree_raw+\";\", format=0)\n",
    "    print(\"Gene tree is infered with length of\",len(gene_tree),\".\")\n",
    "\n",
    "    #gene_tree_i +=1\n",
    "    R = gene_tree.get_midpoint_outgroup()\n",
    "    gene_tree.set_outgroup(R)\n",
    "    #print(\"Midpoint rooting is done for gene tree.\")\n",
    "\n",
    "    gene_tree = lable_SD_internal_nodes(gene_tree)\n",
    "    print(\"Overlap speciation is done for internal nodes of gene tree.\")\n",
    "    print(str(gene_tree.write(format=1))[:-1]+str(gene_tree.name)+\":0;\")\n",
    "    #print(gene_tree)\n",
    "\n",
    "    subHOG_thisLevel = []\n",
    "    # for  each speciestion node\n",
    "        #HOG([ sub hog  for in withing speciestion node], msa= merged_msa    )\n",
    "    \n",
    "    (assigned_leaves_to_hog, sub_msas_list_this_level) = traverse_geneTree_assign_hog(gene_tree, merged_msa)\n",
    "\n",
    "    tree_leaves = [ i.name for i in gene_tree.get_leaves()] \n",
    "    if set(tree_leaves)-set(assigned_leaves_to_hog) :\n",
    "        print(\"error 234\",assigned_leaves_to_hog, sub_msas_list_this_level)\n",
    "\n",
    "    dic_sub_msas[node_species_tree.name] = sub_msas_list_this_level \n",
    "    print(\"Number of hog at the taxonomic level\", node_species_tree.name ,\"is \",len(sub_msas_list_this_level),\". The number of proteins per hog is\", [len(i) for i in  sub_msas_list_this_level])    \n",
    "\n",
    "    # compare with  subHOG_lowerLevel merge if needed two are from different \n",
    "    subHOG_thisLevel =[]\n",
    "    for submsa in sub_msas_list_this_level :\n",
    "        subHOG_thisLevel.append([seq.id for seq in submsa])\n",
    "    #print(\"subHOGs are:\", subHOG_thisLevel)\n",
    "\n",
    "    paralog_set_thisLevel = find_paralog_thisLevel(tree_leaves, subHOG_thisLevel)\n",
    "\n",
    "    return (subHOG_thisLevel, paralog_set_thisLevel, dic_sub_msas)\n",
    "\n",
    "\n",
    "\n",
    "def write_ortholog_rhog(parlog_set_rhog, prot_names_rhog, address_orhto_pair_file):\n",
    "\n",
    "    all_pairs= set()\n",
    "    for i in range(len(prot_names_rhog)):\n",
    "        for j in range(i+1):\n",
    "            prot_i = prot_names_rhog[i]\n",
    "            prot_j = prot_names_rhog[j]\n",
    "            all_pairs.add((prot_i,prot_j))\n",
    "         \n",
    "    #print(all_pairs)\n",
    "    #print(\"para\", parlog_set_rhog)\n",
    "    file_ortho = open(address_orhto_pair_file, \"a\")\n",
    "    for pair in all_pairs:\n",
    "        if pair not in parlog_set_rhog:\n",
    "            prot_i_5letter= pair[0].split(\"|\")[1].strip()\n",
    "            prot_j_5letter= pair[1].split(\"|\")[1].strip()\n",
    "            #print(\"**ortho pair is**\",prot_i_5letter,prot_j_5letter)\n",
    "            file_ortho.write(prot_i_5letter+\"\\t\"+prot_j_5letter+\"\\n\")\n",
    "            \n",
    "    file_ortho.close() \n",
    "    \n",
    "    print(\"Some ortho pairs are appended in\", address_orhto_pair_file)\n",
    "\n",
    "    return 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def traverse_speciesTree_inferHOG(species_tree, rhog_i, species_names_rhog, rhogid_num, prot_names_rhog):\n",
    "\n",
    "    subHOG_all = []\n",
    "    dic_sub_msas = {}\n",
    "    parlog_set_rhog = set()\n",
    "\n",
    "    # finding hogs at each level of species tree (from leaves to root, bottom up)    \n",
    "    for node_species_tree in species_tree.traverse(strategy = \"postorder\"):\n",
    "        #dic_sub_hogs[node_species_tree.name] = []\n",
    "        dic_sub_msas[node_species_tree.name] = []\n",
    "        if node_species_tree.is_leaf() : \n",
    "            continue\n",
    "        print(\"\\n\"+\"*\"*15+\"\\n\",\"Finding hogs for the taxonomic level:\", node_species_tree.name,\"\\n\")\n",
    "\n",
    "        (subHOG_thisLevel, paralog_set_thisLevel, dic_sub_msas)=  infer_HOG_thisLevel(node_species_tree, rhog_i, species_names_rhog, dic_sub_msas, rhogid_num)\n",
    "        if subHOG_thisLevel == -1: continue\n",
    "        \n",
    "        print(\"subHOG_thisLevel\",subHOG_thisLevel)\n",
    "        subHOG_all.append(subHOG_thisLevel)\n",
    "        \n",
    "        parlog_set_rhog |= paralog_set_thisLevel\n",
    "\n",
    "        \n",
    "    write_ortho = write_ortholog_rhog(parlog_set_rhog, prot_names_rhog, address_orhto_pair_file)\n",
    "\n",
    "\n",
    "    return (subHOG_all)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def run_inference(rhogid_num):\n",
    "\n",
    "    print(\"\\n\"+\"=\"*50+\"\\n\",\"Working on root hog:\", rhogid_num,\"\\n\") \n",
    "\n",
    "    prot_address = address_out_hog+\"HOG_\"+str(rhogid_num)+\".fa\"\n",
    "    rhog_i = list(SeqIO.parse(prot_address, \"fasta\")) \n",
    "    print(\"number of proteins in the rHOG\", len(rhog_i))\n",
    "    (species_tree) = read_species_tree(tree_address)\n",
    "    (species_tree, species_names_rhog, prot_names_rhog) = prepare_species_tree(rhog_i, species_tree)\n",
    "\n",
    "    if len(rhog_i) ==1:\n",
    "        subHOG_all_rhog = [prot_names_rhog]\n",
    "        ortholog_set_rhog = set()\n",
    "        \n",
    "    else:\n",
    "        (subHOG_all_rhog) = traverse_speciesTree_inferHOG(species_tree, rhog_i, species_names_rhog, rhogid_num, prot_names_rhog)\n",
    "    \n",
    "    print(\"Working on root hog:\", rhogid_num,\" is finished.\\n\"+\"=\"*50+\"\\n\") \n",
    "\n",
    "    return (subHOG_all_rhog ) \n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "#from scipy.cluster.hierarchy import dendrogram, linkage, ward, leaves_list, fcluster\n",
    "\n",
    "import ete3\n",
    "from ete3 import Tree\n",
    "from ete3 import Phyloxml\n",
    "\n",
    "import numpy as np\n",
    "import pyoma.browser.db as db\n",
    "import concurrent.futures\n",
    "#import ast\n",
    "#import pickle\n",
    "#import zoo\n",
    "#zoo.__file__\n",
    "\n",
    "import os\n",
    "\n",
    "from pyoma.browser.models import ProteinEntry\n",
    "import pyoma.browser.db as db\n",
    "from pyoma.browser.hoghelper import build_hog_to_og_map\n",
    "\n",
    "import zoo.wrappers.aligners.mafft as mafft  # mafft should be installed beforehand\n",
    "import zoo.wrappers.treebuilders.fasttree as fasttree\n",
    "import logging\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "from sys import argv\n",
    "from os import listdir\n",
    "import os\n",
    "from Bio import SeqIO\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Seq import Seq, UnknownSeq\n",
    "from Bio.Align import MultipleSeqAlignment\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib   #for development \n",
    "#matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df094512",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6db34cc8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "\n",
    "#     print(\"program is started \")\n",
    "#     address_working_folder = \"/work/FAC/FBM/DBC/cdessim2/default/smajidi1/fastget/qfo/\"\n",
    "#     address_out_hog= address_working_folder+ \"hog_out_g2_s100/\"\n",
    "    \n",
    "#     rHog_is_ready= False \n",
    "#     if not rHog_is_ready : \n",
    "\n",
    "\n",
    "#         oma_database_address = address_working_folder+\"omamer_database/oma_path/OmaServer.h5\"\n",
    "#         print(\"program has started. The oma database address is in \",oma_database_address)\n",
    "#         (oma_db, list_oma_speices) = parse_oma_db(oma_database_address)\n",
    "#         (query_species_names, query_prot_records_species) = parse_proteome(list_oma_speices)   \n",
    "#         query_prot_records_species = add_species_name(query_prot_records_species,query_species_names)\n",
    "\n",
    "#         hogmap_allspecies = parse_hogmap_omamer(query_species_names)\n",
    "#         (query_prot_names_species_mapped, prots_hogmap_hogid_allspecies, prots_hogmap_subfscore_allspecies, prots_hogmap_seqlen_allspecies, prots_hogmap_subfmedseqlen_allspecies) = hogmap_allspecies \n",
    "#         query_prot_records_species_filtered =  filter_prot_mapped(query_species_names, query_prot_records_species, query_prot_names_species_mapped)\n",
    "\n",
    "#         print(len(query_prot_records_species_filtered),len(query_prot_records_species_filtered[0]))\n",
    "\n",
    "#         ## Write  rootHoGs as fasta file\n",
    "#         (rhogid_num_list, rhogids_prot_records_query) =  write_rootHOGs(prots_hogmap_hogid_allspecies, address_out_hog)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9dc6cd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a970d9f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "#     print(\"program is started \")\n",
    "    \n",
    "#     address_working_folder = \"/work/FAC/FBM/DBC/cdessim2/default/smajidi1/fastget/qfo/\"\n",
    "#     address_out_hog= address_working_folder+ \"hog_out_g2_s100/\"\n",
    "    \n",
    "#     rHog_is_ready= True \n",
    "#     if not rHog_is_ready : pass\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "#     tree_address = address_working_folder+\"lineage_tree_qfo.phyloxml\"\n",
    "    \n",
    "#     rhog_files = listdir(address_out_hog)\n",
    "#     rhogid_num_list= []\n",
    "#     for rhog_file in rhog_files:\n",
    "#         if rhog_file.split(\".\")[-1] == \"fa\":\n",
    "#             rhogid_num = int(rhog_file.split(\".\")[0].split(\"_\")[1])\n",
    "#             rhogid_num_list.append(rhogid_num)\n",
    "\n",
    "    \n",
    "#     try : \n",
    "#         rhogid_num_list2 = rhogid_num_list[1002:1110] #[159556, 105904] #rhogid_num_list[2000:2010]\n",
    "#         dic_solved={}\n",
    "#         list_done=[]\n",
    "#         for i in rhogid_num_list2: dic_solved[i] = 0\n",
    "\n",
    "#         subHOG_all= [] # list of list\n",
    "#         # make sure the file is empty\n",
    "#         address_orhto_pair_file =  address_working_folder+\"ortho_pair_first.tsv\"\n",
    "#         file_ortho = open(address_orhto_pair_file, \"w\")\n",
    "#         file_ortho.close()\n",
    "\n",
    "\n",
    "#         print(\"parrallel is started\")\n",
    "#         number_max_workers = 20\n",
    "#         with concurrent.futures.ProcessPoolExecutor(max_workers = number_max_workers) as executor: \n",
    "#             for rhogid_num, output_values in zip(rhogid_num_list2, executor.map(run_inference, rhogid_num_list2)):\n",
    "#                 (subHOG_all_rhog) = output_values\n",
    "#                 dic_solved[rhogid_num]=1\n",
    "#                 list_done.append(rhogid_num)\n",
    "                \n",
    "\n",
    "\n",
    "#         print(\"all done !!\")\n",
    "#         print(\"program is finished \")\n",
    "#     except:\n",
    "#         print(\"program faced an error \",rhogid_num)        \n",
    "#         print(\"all\",rhogid_num_list2)\n",
    "#         print(\"****** done\", list_done)\n",
    "#         index_last= rhogid_num_list2.index(list_done[-1])\n",
    "#         print(index_last)\n",
    "#         print(rhogid_num_list2[index_last-1:index_last+5])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17a2141c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "address_working_folder = \"/work/FAC/FBM/DBC/cdessim2/default/smajidi1/fastget/qfo/\"\n",
    "address_out_hog= address_working_folder+ \"hog_out_g2_s100/\"\n",
    "\n",
    "rHog_is_ready= True \n",
    "if not rHog_is_ready : pass\n",
    "\n",
    "tree_address = address_working_folder+\"lineage_tree_qfo.phyloxml\"\n",
    "\n",
    "rhog_files = listdir(address_out_hog)\n",
    "rhogid_num_list= []\n",
    "for rhog_file in rhog_files:\n",
    "    if rhog_file.split(\".\")[-1] == \"fa\":\n",
    "        rhogid_num = int(rhog_file.split(\".\")[0].split(\"_\")[1])\n",
    "        rhogid_num_list.append(rhogid_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "104ca913",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135730"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rhogid_num_list[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cefe506",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20600079",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afc07526",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "subHOG_all= [] # list of list\n",
    "\n",
    "address_orhto_pair_file =  address_working_folder+\"ortho_pair_first_test.tsv\"\n",
    "file_ortho = open(address_orhto_pair_file, \"w\")\n",
    "file_ortho.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9bb4b416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      " Working on root hog: 243421 \n",
      "\n",
      "number of proteins in the rHOG 5\n",
      "/work/FAC/FBM/DBC/cdessim2/default/smajidi1/fastget/qfo/lineage_tree_qfo.phyloxml\n",
      "number of unique species in the rHOG 3\n",
      "Working on the following species tree.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n\"+\"=\"*50+\"\\n\",\"Working on root hog:\", rhogid_num,\"\\n\") \n",
    "\n",
    "prot_address = address_out_hog+\"HOG_\"+str(rhogid_num)+\".fa\"\n",
    "rhog_i = list(SeqIO.parse(prot_address, \"fasta\")) \n",
    "print(\"number of proteins in the rHOG\", len(rhog_i))\n",
    "(species_tree) = read_species_tree(tree_address)\n",
    "\n",
    "(species_tree, species_names_rhog, prot_names_rhog) = prepare_species_tree(rhog_i, species_tree)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f8a5ed2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ORYSJ', 'ORYSJ', 'MAIZE', 'ARATH', 'ARATH']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "species_names_rhog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ce29bd91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((ORYSJ:0,MAIZE:0)1:0,ARATH:0);\n",
      "\n",
      "      /-ORYSJ\n",
      "   /-|\n",
      "--|   \\-MAIZE\n",
      "  |\n",
      "   \\-ARATH\n"
     ]
    }
   ],
   "source": [
    "species_tree.write()\n",
    "print(species_tree.write())\n",
    "print(species_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "763f63f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'((ORYSJ:0,MAIZE:0)1:0,ARATH:0);'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# species_tree.prune([\"ORYSJ\",\"MAIZE\"])\n",
    "\n",
    "# #print(node_species_tree)\n",
    "# #node_species_tree.write()\n",
    "# species_tree.name = 'ORYSJ_MAIZE'\n",
    "species_tree.write()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d7c064",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e966be78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a54a709f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ORYSJ_MAIZE': [<__main__.HOG at 0x7fe9af37a430>,\n",
       "  <__main__.HOG at 0x7fe9af2a9ee0>]}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic_sub_hogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "27c88b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***************\n",
      " Finding hogs for the taxonomic level: ORYSJ_MAIZE \n",
      "\n",
      "working on node ORYSJ_MAIZE with 2 children.\n",
      "len 2\n",
      "****  hog138\n",
      "****  hog139\n",
      "len 1\n",
      "****  hog140\n",
      "there are  3 subHOGs lower of this level. \n",
      "We want to infer subHOGs at this level,i.e. merge few of them.\n",
      "3 msas are merged into one with the length of  3 606\n",
      "All subHOGs are merged, merged msa is with length of 3 606 .\n",
      "Gene tree is infered with length of 3 .\n",
      "Overlap speciation is done for internal nodes of gene tree.\n",
      "(tr|A0A0P0WQK1|A0A0P0WQK1_ORYSJ:0.514901,(tr|A0A0P0WQD6|A0A0P0WQD6_ORYSJ:0.0448269,tr|A0A1D6M2D7|A0A1D6M2D7_MAIZE:0.275836)S1:0.514901)D1:0;\n",
      "['tr|A0A0P0WQK1|A0A0P0WQK1_ORYSJ', 'tr|A0A0P0WQD6|A0A0P0WQD6_ORYSJ', 'tr|A0A1D6M2D7|A0A1D6M2D7_MAIZE']\n",
      "['tr|A0A0P0WQD6|A0A0P0WQD6_ORYSJ', 'tr|A0A1D6M2D7|A0A1D6M2D7_MAIZE']\n",
      "****  hog141\n",
      "here <__main__.HOG object at 0x7feb687f2f70>\n",
      "HOG_this_level [{'tr|A0A1D6M2D7|A0A1D6M2D7_MAIZE', 'tr|A0A0P0WQD6|A0A0P0WQD6_ORYSJ'}, {'tr|A0A0P0WQK1|A0A0P0WQK1_ORYSJ'}]\n",
      "\n",
      "***************\n",
      " Finding hogs for the taxonomic level: ORYSJ_MAIZE_ARATH \n",
      "\n",
      "working on node ORYSJ_MAIZE_ARATH with 2 children.\n",
      "sub msa for internal node ORYSJ_MAIZE is read from dic.\n",
      "len 2\n",
      "****  hog142\n",
      "****  hog143\n",
      "there are  4 subHOGs lower of this level. \n",
      "We want to infer subHOGs at this level,i.e. merge few of them.\n",
      "4 msas are merged into one with the length of  5 606\n",
      "All subHOGs are merged, merged msa is with length of 5 606 .\n",
      "Gene tree is infered with length of 5 .\n",
      "Overlap speciation is done for internal nodes of gene tree.\n",
      "(tr|A0A0P0WQK1|A0A0P0WQK1_ORYSJ:0.651241,(tr|A0A0P0WQD6|A0A0P0WQD6_ORYSJ:0.0392759,((sp|Q8W4D8|DDL_ARATH:0.072339,tr|Q9ZQ27|Q9ZQ27_ARATH:0.437672)D1:0.430273,tr|A0A1D6M2D7|A0A1D6M2D7_MAIZE:0.206306)S1:0.0738488)S2:0.651241)D2:0;\n",
      "['tr|A0A0P0WQK1|A0A0P0WQK1_ORYSJ', 'tr|A0A0P0WQD6|A0A0P0WQD6_ORYSJ', 'sp|Q8W4D8|DDL_ARATH', 'tr|Q9ZQ27|Q9ZQ27_ARATH', 'tr|A0A1D6M2D7|A0A1D6M2D7_MAIZE']\n",
      "['tr|A0A0P0WQD6|A0A0P0WQD6_ORYSJ', 'sp|Q8W4D8|DDL_ARATH', 'tr|Q9ZQ27|Q9ZQ27_ARATH', 'tr|A0A1D6M2D7|A0A1D6M2D7_MAIZE']\n",
      "****  hog144\n",
      "['sp|Q8W4D8|DDL_ARATH', 'tr|Q9ZQ27|Q9ZQ27_ARATH', 'tr|A0A1D6M2D7|A0A1D6M2D7_MAIZE']\n",
      "****  hog145\n",
      "['sp|Q8W4D8|DDL_ARATH', 'tr|Q9ZQ27|Q9ZQ27_ARATH']\n",
      "here <__main__.HOG object at 0x7feb687f2f70>\n",
      "HOG_this_level [{'tr|A0A1D6M2D7|A0A1D6M2D7_MAIZE', 'tr|A0A0P0WQD6|A0A0P0WQD6_ORYSJ', 'sp|Q8W4D8|DDL_ARATH', 'tr|Q9ZQ27|Q9ZQ27_ARATH'}, {'tr|A0A1D6M2D7|A0A1D6M2D7_MAIZE', 'tr|A0A0P0WQD6|A0A0P0WQD6_ORYSJ', 'sp|Q8W4D8|DDL_ARATH', 'tr|Q9ZQ27|Q9ZQ27_ARATH'}, {'tr|A0A0P0WQK1|A0A0P0WQK1_ORYSJ'}]\n"
     ]
    }
   ],
   "source": [
    "#subHOG_all = []\n",
    "dic_sub_hogs = {}\n",
    "#parlog_set_rhog = set()\n",
    "\n",
    "# finding hogs at each level of species tree (from leaves to root, bottom up)    \n",
    "for node_species_tree in species_tree.traverse(strategy = \"postorder\"):\n",
    "    #dic_sub_hogs[node_species_tree.name] = []\n",
    "    #dic_sub_msas[node_species_tree.name] = []\n",
    "    if node_species_tree.is_leaf() : \n",
    "        continue\n",
    "    print(\"\\n\"+\"*\"*15+\"\\n\",\"Finding hogs for the taxonomic level:\", node_species_tree.name,\"\\n\")\n",
    "    dic_sub_hogs = infer_HOG_thisLevel(node_species_tree, rhog_i, species_names_rhog, dic_sub_msas, rhogid_num)\n",
    "    #(subHOG_thisLevel, paralog_set_thisLevel, dic_sub_msas)=  infer_HOG_thisLevel(node_species_tree, rhog_i, species_names_rhog, dic_sub_msas, rhogid_num)\n",
    "\n",
    "#write_ortho = write_ortholog_rhog(parlog_set_rhog, prot_names_rhog, address_orhto_pair_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb6a32c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #(subHOG_all_rhog) = traverse_speciesTree_inferHOG(species_tree, rhog_i, species_names_rhog, rhogid_num, prot_names_rhog)\n",
    "\n",
    "# #sub_msa_list_lowerLevel = [] # including subHOGS of lower level \n",
    "# for node_child in node_species_tree.children:\n",
    "#     if  node_child.is_leaf():\n",
    "#         node_species_name = node_child.name\n",
    "#         # for a extant species \n",
    "#         # extracting prot sequeincg of the species from the rootHOG\n",
    "#         interest_list = [idx  for idx in range(len(species_names_rhog)) if species_names_rhog[idx] == node_species_name ]\n",
    "#         rhog_part = [rhog_i[i] for i in interest_list]\n",
    "#         #sub_msa = [MultipleSeqAlignment([i]) for i in rhog_part] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d029510",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7862c12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class HOG:\n",
    "    \n",
    "#     _hogid_iter = 100 \n",
    "#     def __init__(self, sub_hogs, msa=None):       \n",
    "        \n",
    "#         # sub_hogs is a list of biopython seq record\n",
    "#         #  [ SeqRecord(seq=Seq('MAPSSRSPSPRT. ] \n",
    "        \n",
    "#         self.__class__._hogid_iter += 1\n",
    "#         self._hogid= \"hog\"+str(self.__class__._hogid_iter)\n",
    "#         print(\"**** \", self._hogid)\n",
    "#         if len(sub_hogs)==1:\n",
    "#             # only one seq, only on child, leaf            \n",
    "#             # <<class 'Bio.Align.MultipleSeqAlignment'> instance (1 records of length 314) at 7f0e86c713d0>\n",
    "            \n",
    "#             self._members = set([sub_hogs[0].id])\n",
    "#             self._msa =  MultipleSeqAlignment(sub_hogs)\n",
    "            \n",
    "            \n",
    "#         elif len(sub_hogs)>1: # the node has few children \n",
    "#             print(\"when there are few item in sub_hogs, msa should be proivded as argument\")\n",
    "#             assert msa\n",
    "            \n",
    "#             hog_members = set()\n",
    "#             for sub_hog in sub_hogs: \n",
    "#                 hog_members |= sub_hog.get_members()  #union\n",
    "#             self._members =  hog_members              #set.union(*tup) \n",
    "            \n",
    "#             self._msa =  MultipleSeqAlignment([record for record in msa if record.id in self._members])\n",
    "#         else:\n",
    "#             print(\"the input sub_hogs for creating the object of class HOG is empty\",len(sub_hogs))\n",
    "#             pass\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "#     def get_members(self):\n",
    "#         return set(self._members)\n",
    "        \n",
    "#         #merge, gene tree, midpoint, lable_SD_internal_nodes, traverse_geneTree_assign_hog\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2630e4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6da864a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f39193a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HOG:\n",
    "    \n",
    "    _hogid_iter = 100 \n",
    "    def __init__(self, input_instantiate , msa = None):       # _prot_names\n",
    "        \n",
    "        # the input_instantiate could be either\n",
    "        #     1) a protein as the biopython seq record  SeqRecord(seq=Seq('MAPSSRSPSPRT. ] \n",
    "        # or  2) a set of intances of class HOG   wit a big msa\n",
    "        \n",
    "        \n",
    "        self.__class__._hogid_iter += 1\n",
    "        self._hogid= \"hog\"+str(self.__class__._hogid_iter)\n",
    "        print(\"**** \", self._hogid)\n",
    "        \n",
    "        if  isinstance(input_instantiate, SeqRecord):    #if len(sub_hogs)==1:\n",
    "            only_protein = input_instantiate\n",
    "            # only one seq, only on child, leaf            \n",
    "            self._members = set([only_protein.id])\n",
    "            self._msa =  MultipleSeqAlignment([only_protein])\n",
    "            # <<class 'Bio.Align.MultipleSeqAlignment'> instance (1 records of length 314) at 7f0e86c713d0>\n",
    "            \n",
    "        elif     msa    and   all(isinstance(x, HOG) for x in input_instantiate):  \n",
    "            # here we want to merge few subHOGs and creat a new HOG.\n",
    "            # the n\n",
    "            \n",
    "            sub_hogs = input_instantiate\n",
    "            \n",
    "            hog_members = set()\n",
    "            for sub_hog in sub_hogs: \n",
    "                hog_members |= sub_hog.get_members()  #union\n",
    "            self._members =  hog_members              #set.union(*tup) \n",
    "            \n",
    "            # now select those proteins \n",
    "            self._msa =  MultipleSeqAlignment([record for record in msa if record.id in self._members])\n",
    "        \n",
    "            # self._children = sub_hogs # as legacy  ?\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            print(\"Error 136,  check the input format to instantiate a HOG class\")\n",
    "            assert False\n",
    "\n",
    "            \n",
    "    def get_members(self):\n",
    "        return set(self._members)\n",
    "        \n",
    "        #merge, gene tree, midpoint, lable_SD_internal_nodes, traverse_geneTree_assign_hog\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d8c9c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22887abd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04eb021c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad67183",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2e508d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def infer_HOG_thisLevel(node_species_tree, rhog_i, species_names_rhog, dic_sub_msas, rhogid_num):\n",
    "\n",
    "    #list_all_hogs_ever = []\n",
    "    #dic_sub_hogs={}\n",
    "    #if 1#:\n",
    "    #def infer_HOG_thisLevel(node_species_tree, rhog_i, species_names_rhog, dic_sub_msas, rhogid_num):\n",
    "    #def infer_HOG_thisLevel(node_species_tree, rhog_i, species_names_rhog, dic_sub_hogs, rhogid_num):\n",
    "    #    return (subHOG_thisLevel, paralog_set_thisLevel, dic_sub_msas)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    sub_msa_list_lowerLevel = [] # including subHOGS of lower level \n",
    "    subHOGs_children = []\n",
    "\n",
    "    print(\"working on node\", node_species_tree.name,\"with\",len(node_species_tree.children),\"children.\")\n",
    "    for node_child in node_species_tree.children:\n",
    "        if  node_child.is_leaf():\n",
    "            node_species_name = node_child.name\n",
    "            #extracting those proteins of the rHOG that belongs to this species (child node of species tree)             \n",
    "            interest_list = [idx  for idx in range(len(species_names_rhog)) if species_names_rhog[idx] == node_species_name ]\n",
    "            rhog_part = [rhog_i[i] for i in interest_list]\n",
    "            #sub_msa = [MultipleSeqAlignment([i]) for i in rhog_part] \n",
    "            print(\"len\",len(rhog_part))\n",
    "\n",
    "            #sub_hog_leaf_list=[]\n",
    "            for prot in rhog_part : \n",
    "                sub_hog_leaf = HOG(prot)\n",
    "                #list_all_hogs_ever.append(sub_hog_leaf)\n",
    "                subHOGs_children.append(sub_hog_leaf)                \n",
    "                #sub_hog_leaf_list.append(sub_hog_leaf)\n",
    "            #sub_msa = sub_hog_leaf_list\n",
    "\n",
    "        else:   # the child node is an internal node, subHOGs are inferred till now during traversing.\n",
    "\n",
    "            print(\"sub msa for internal node\", node_child.name,\"is read from dic.\")\n",
    "            #if node_child.name in dic_sub_msas:\n",
    "                #sub_msa  = dic_sub_msas[node_child.name]\n",
    "            if node_child.name in dic_sub_hogs:\n",
    "                sub_hogs_child  = dic_sub_hogs[node_child.name]\n",
    "                subHOGs_children += sub_hogs_child\n",
    "            else:\n",
    "                print(\"error 131, no sub msa for the internal node \",node_child.name, node_child)\n",
    "                assert 2==1 \n",
    "\n",
    "\n",
    "    print(\"there are \",len(subHOGs_children),\"subHOGs lower of this level. \")\n",
    "    print(\"We want to infer subHOGs at this level,i.e. merge few of them.\")    \n",
    "\n",
    "\n",
    "    # sub_msa_list_lowerLevel += sub_msa\n",
    "\n",
    "    #     if len(sub_msa_list_lowerLevel) <2:\n",
    "    #         print(\"**** issue **  \", len(sub_msa_list_lowerLevel),sub_msa_list_lowerLevel)\n",
    "    #         #return (-1,-1,-1)\n",
    "\n",
    "    if len(subHOGs_children) <2:\n",
    "        print(\"**** error 134 *** \", len(subHOGs_children),subHOGs_children)\n",
    "            #return (-1,-1,-1)\n",
    "    else:\n",
    "\n",
    "        sub_msa_list_lowerLevel_ready = [hog._msa for hog in subHOGs_children]\n",
    "        merged_msa = merge_msa(sub_msa_list_lowerLevel_ready) \n",
    "\n",
    "        print(\"All subHOGs are merged, merged msa is with length of\",len(merged_msa), len(merged_msa[0]),\".\")\n",
    "\n",
    "        gene_tree_file =  address_working_folder + \"/gene_trees_test/tree_\"+str(rhogid_num)+\"_\"+str(node_species_tree.name)+\".nwk\"\n",
    "\n",
    "\n",
    "        gene_tree_raw = draw_tree(merged_msa, gene_tree_file)\n",
    "        gene_tree = Tree(gene_tree_raw+\";\", format=0)\n",
    "        print(\"Gene tree is infered with length of\",len(gene_tree),\".\")\n",
    "\n",
    "        #gene_tree_i +=1\n",
    "        R = gene_tree.get_midpoint_outgroup()\n",
    "        gene_tree.set_outgroup(R)\n",
    "        #print(\"Midpoint rooting is done for gene tree.\")\n",
    "\n",
    "        gene_tree = lable_SD_internal_nodes(gene_tree)\n",
    "        print(\"Overlap speciation is done for internal nodes of gene tree.\")\n",
    "        print(str(gene_tree.write(format=1))[:-1]+str(gene_tree.name)+\":0;\")\n",
    "        #print(gene_tree)\n",
    "\n",
    "\n",
    "\n",
    "        #(assigned_leaves_to_hog, sub_msas_list_this_level) = traverse_geneTree_assign_hog(gene_tree, merged_msa)\n",
    "\n",
    "        tree_leaves = [i.name for i in gene_tree.get_leaves() ]\n",
    "        #assigned_leaves_to_hog = []\n",
    "        #sub_msas_list_this_level = []\n",
    "        subHOGs_id_children_assigned = [] # the same as  subHOG_to_be_merged_all_id \n",
    "        HOG_this_level = []\n",
    "        subHOG_to_be_merged_set_other_Snodes = []\n",
    "\n",
    "        for node in gene_tree.traverse(strategy = \"preorder\"): # start from root\n",
    "            #print(\"Leaves assigned to hog are \", assigned_leaves_to_hog)\n",
    "            #print(\"Traversing gene tree. Now at node\", node.name)\n",
    "\n",
    "            if not node.is_leaf() : \n",
    "                node_leaves_name = [ i.name for i in node.get_leaves() ] \n",
    "                print(node_leaves_name)\n",
    "\n",
    "                if node.name[0] ==\"S\":\n",
    "                    # this is a sub-hog.\n",
    "\n",
    "                    subHOG_to_be_merged = [ ]\n",
    "                    for node_leave_name in node_leaves_name:\n",
    "\n",
    "                        #print(node_leave_name)\n",
    "\n",
    "                        for subHOG in subHOGs_children :\n",
    "                            subHOG_members= subHOG._members\n",
    "                            if node_leave_name in subHOG_members:\n",
    "\n",
    "                                subHOG_to_be_merged.append(subHOG)\n",
    "                                subHOGs_id_children_assigned.append(subHOG._hogid)\n",
    "                                # print(node_leave_name,\"is in \",subHOG._hogid)\n",
    "                    subHOG_to_be_merged_set = set(subHOG_to_be_merged)     \n",
    "                    HOG_this_node = HOG(subHOG_to_be_merged_set, merged_msa) \n",
    "                    HOG_this_level.append(HOG_this_node)\n",
    "                    subHOG_to_be_merged_set_other_Snodes.append([i._hogid for i in subHOG_to_be_merged_set])\n",
    "\n",
    "        for subHOG in subHOGs_children :      \n",
    "            # for the single branch  ( D include a  subhog and a S node. )\n",
    "            if  subHOG._hogid  not in subHOGs_id_children_assigned : \n",
    "                print(\"here\", subHOG)\n",
    "                HOG_this_level.append(subHOG)\n",
    "        print(\"HOG_this_level\", [i._members for i in HOG_this_level])\n",
    "\n",
    "        #check for conflic in merging\n",
    "    #     for i in range(subHOG_to_be_merged_set_other_Snodes):\n",
    "    #         if \n",
    "    #         for i in range(subHOG_to_be_merged_set_other_Snodes):\n",
    "\n",
    "    dic_sub_hogs[node_species_tree.name] = HOG_this_level\n",
    "    \n",
    "    return dic_sub_hogs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "64f72a9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(prot, SeqRecord) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3703ff8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "37f57efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tr|A0A0P0WQK1|A0A0P0WQK1_ORYSJ', 'tr|A0A0P0WQD6|A0A0P0WQD6_ORYSJ', 'tr|A0A1D6M2D7|A0A1D6M2D7_MAIZE']\n",
      "['tr|A0A0P0WQD6|A0A0P0WQD6_ORYSJ', 'tr|A0A1D6M2D7|A0A1D6M2D7_MAIZE']\n",
      "****  hog109\n",
      "here <__main__.HOG object at 0x7feb687f2d60>\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000b2197",
   "metadata": {},
   "outputs": [],
   "source": [
    "subHOG_to_be_merged_set_other_Snodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524d2566",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a909a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965467ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd962121",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb1d150",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0872a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# if 1:    \n",
    "# #def traverse_geneTree_assign_hog(gene_tree, merged_msa):\n",
    "#     # gene_tree should be labeled with S/ D\n",
    "#     tree_leaves = [ i.name for i in gene_tree.get_leaves()] \n",
    "#     assigned_leaves_to_hog = []\n",
    "#     sub_msas_list_this_level = []\n",
    "\n",
    "#     for node in gene_tree.traverse(strategy = \"preorder\"): # start from root\n",
    "#         #print(\"Leaves assigned to hog are \", assigned_leaves_to_hog)\n",
    "#         #print(\"Traversing gene tree. Now at node\", node.name)\n",
    "\n",
    "#         if node.is_root() and node.name[0] == \"S\":    \n",
    "#             sub_msas_list_this_level = [merged_msa]\n",
    "#             assigned_leaves_to_hog = tree_leaves\n",
    "#             # we do not need to traverse the gene tree any more \n",
    "#             break\n",
    "\n",
    "#         if not node.is_leaf() : \n",
    "#             node_leaves_name = [ i.name for i in node.get_leaves() ] \n",
    "            \n",
    "#             # ?? ?? \n",
    "#             if node_leaves_name[0] in assigned_leaves_to_hog:\n",
    "#                 # if one of them is there, since  preorder,  all should be there ???    \n",
    "#                 # the node are assigned to hogs, we are done. \n",
    "#                 # it is not needed to check the children of a speciecation\n",
    "#                 continue  # go to next node\n",
    "\n",
    "#             if node.name[0] ==\"S\":\n",
    "#                 # this is a sub-hog.\n",
    "#                 assigned_leaves_to_hog += node_leaves_name\n",
    "#                 leaves_msa = [i.id for i in merged_msa]\n",
    "#                 idx_species_list = [leaves_msa.index(i) for i in node_leaves_name] \n",
    "#                 #print(\"idx_species_list\",idx_species_list)\n",
    "#                 #print(\"node_leaves_name\",node_leaves_name)\n",
    "                \n",
    "#                 sub_msa_seq_list = [  merged_msa[i]   for i in idx_species_list]  # sub_msas_list_lowerlevel \n",
    "#                 sub_msa = run_one_msa(sub_msa_seq_list)\n",
    "#                 sub_msas_list_this_level.append(sub_msa)\n",
    "\n",
    "#                 if  set(tree_leaves)==set(assigned_leaves_to_hog) :\n",
    "#                     # all leaves are assigned to hogs, we are done. \n",
    "#                     break\n",
    "\n",
    "#         if node.is_leaf() and not node.name in assigned_leaves_to_hog:\n",
    "#             #  singletone leaf, can be a hog. \n",
    "#             assigned_leaves_to_hog.append(node.name)\n",
    "#             #print(\"assigned_leaves_to_hog\",assigned_leaves_to_hog)\n",
    "#             leaves_msa = [i.id for i in merged_msa]\n",
    "#             #print(\"leaves_msa\",leaves_msa)\n",
    "\n",
    "#             idx_species = leaves_msa.index(node.name)\n",
    "#             sub_msa = MultipleSeqAlignment([merged_msa[idx_species]])\n",
    "#             sub_msas_list_this_level.append(sub_msa)\n",
    "            \n",
    "# #    return (assigned_leaves_to_hog, sub_msas_list_this_level)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195dcd45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c938d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d7fcbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa00bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# if 1:    \n",
    "# #def traverse_geneTree_assign_hog(gene_tree, merged_msa):\n",
    "#     # gene_tree should be labeled with S/ D\n",
    "#     tree_leaves = [ i.name for i in gene_tree.get_leaves()] \n",
    "#     assigned_leaves_to_hog = []\n",
    "#     sub_msas_list_this_level = []\n",
    "\n",
    "#     for node in gene_tree.traverse(strategy = \"preorder\"): # start from root\n",
    "#         #print(\"Leaves assigned to hog are \", assigned_leaves_to_hog)\n",
    "#         #print(\"Traversing gene tree. Now at node\", node.name)\n",
    "\n",
    "#         if node.is_root() and node.name[0] == \"S\":    \n",
    "#             sub_msas_list_this_level = [merged_msa]\n",
    "#             assigned_leaves_to_hog = tree_leaves\n",
    "#             # we do not need to traverse the gene tree any more \n",
    "#             break\n",
    "\n",
    "#         if not node.is_leaf() : \n",
    "#             node_leaves_name = [ i.name for i in node.get_leaves() ] \n",
    "            \n",
    "#             # ?? ?? \n",
    "#             if node_leaves_name[0] in assigned_leaves_to_hog:\n",
    "#                 # if one of them is there, since  preorder,  all should be there ???    \n",
    "#                 # the node are assigned to hogs, we are done. \n",
    "#                 # it is not needed to check the children of a speciecation\n",
    "#                 continue  # go to next node\n",
    "\n",
    "#             if node.name[0] ==\"S\":\n",
    "#                 # this is a sub-hog.\n",
    "#                 assigned_leaves_to_hog += node_leaves_name\n",
    "#                 leaves_msa = [i.id for i in merged_msa]\n",
    "#                 idx_species_list = [leaves_msa.index(i) for i in node_leaves_name] \n",
    "#                 #print(\"idx_species_list\",idx_species_list)\n",
    "#                 #print(\"node_leaves_name\",node_leaves_name)\n",
    "                \n",
    "#                 sub_msa_seq_list = [  merged_msa[i]   for i in idx_species_list]  # sub_msas_list_lowerlevel \n",
    "#                 sub_msa = run_one_msa(sub_msa_seq_list)\n",
    "#                 sub_msas_list_this_level.append(sub_msa)\n",
    "\n",
    "#                 if  set(tree_leaves)==set(assigned_leaves_to_hog) :\n",
    "#                     # all leaves are assigned to hogs, we are done. \n",
    "#                     break\n",
    "\n",
    "#         if node.is_leaf() and not node.name in assigned_leaves_to_hog:\n",
    "#             #  singletone leaf, can be a hog. \n",
    "#             assigned_leaves_to_hog.append(node.name)\n",
    "#             #print(\"assigned_leaves_to_hog\",assigned_leaves_to_hog)\n",
    "#             leaves_msa = [i.id for i in merged_msa]\n",
    "#             #print(\"leaves_msa\",leaves_msa)\n",
    "\n",
    "#             idx_species = leaves_msa.index(node.name)\n",
    "#             sub_msa = MultipleSeqAlignment([merged_msa[idx_species]])\n",
    "#             sub_msas_list_this_level.append(sub_msa)\n",
    "            \n",
    "# #    return (assigned_leaves_to_hog, sub_msas_list_this_level)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1e5329",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e97a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "hog1= subHOGs_children[0]\n",
    "hog1.get_members()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35dbe817",
   "metadata": {},
   "outputs": [],
   "source": [
    "hog1._hogid,      hog1._hogid_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b517c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "hog1._members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8987722",
   "metadata": {},
   "outputs": [],
   "source": [
    "hog1._msa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4c169c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(hog1._msa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8f3a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(str(gene_tree.write(format=1))[:-1]+str(gene_tree.name)+\":0;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a664e354",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac152e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# #     \n",
    "\n",
    "# #     tree_leaves = [ i.name for i in gene_tree.get_leaves()] \n",
    "# #     if set(tree_leaves)-set(assigned_leaves_to_hog) :\n",
    "# #         print(\"error 234\",assigned_leaves_to_hog, sub_msas_list_this_level)\n",
    "\n",
    "# #     dic_sub_msas[node_species_tree.name] = sub_msas_list_this_level \n",
    "# #     print(\"Number of hog at the taxonomic level\", node_species_tree.name ,\"is \",len(sub_msas_list_this_level),\". The number of proteins per hog is\", [len(i) for i in  sub_msas_list_this_level])    \n",
    "\n",
    "# #     # compare with  subHOG_lowerLevel merge if needed two are from different \n",
    "# #     subHOG_thisLevel =[]\n",
    "# #     for submsa in sub_msas_list_this_level :\n",
    "# #         subHOG_thisLevel.append([seq.id for seq in submsa])\n",
    "# #     #print(\"subHOGs are:\", subHOG_thisLevel)\n",
    "\n",
    "# #     paralog_set_thisLevel = find_paralog_thisLevel(tree_leaves, subHOG_thisLevel)\n",
    "\n",
    "\n",
    "dic_sub_hogs[node_species_tree] = []  #  a list of subhogs\n",
    "\n",
    "\n",
    "# #     return (subHOG_thisLevel, paralog_set_thisLevel, dic_sub_msas)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c473b18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4655ac92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949c0246",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_hog_leaf_list[0].get_members()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6663511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_all_hogs_ever = []\n",
    "\n",
    "\n",
    "\n",
    "# if 1:\n",
    "# #def infer_HOG_thisLevel(node_species_tree, rhog_i, species_names_rhog, dic_sub_msas, rhogid_num):\n",
    "# #    return (subHOG_thisLevel, paralog_set_thisLevel, dic_sub_msas)\n",
    "    \n",
    "#     sub_msa_list_lowerLevel = [] # including subHOGS of lower level \n",
    "#     subHOG_childeren = []\n",
    "    \n",
    "#     for node_child in node_species_tree.children:\n",
    "#         if  node_child.is_leaf():\n",
    "#             node_species_name = node_child.name\n",
    "#             #extracting those proteins of the rHOG that belongs to this species (child node of species tree)             \n",
    "#             interest_list = [idx  for idx in range(len(species_names_rhog)) if species_names_rhog[idx] == node_species_name ]\n",
    "#             rhog_part = [rhog_i[i] for i in interest_list]\n",
    "#             #sub_msa = [MultipleSeqAlignment([i]) for i in rhog_part] \n",
    "            \n",
    "#             #sub_hog_leaf_list=[]\n",
    "#             for prot in rhog_part : \n",
    "#                 sub_hog_leaf = HOG([prot])\n",
    "\n",
    "#                 #list_all_hogs_ever.append(sub_hog_leaf)\n",
    "#                 subHOG_childeren.append(sub_hog_leaf)                \n",
    "#                 #sub_hog_leaf_list.append(sub_hog_leaf)\n",
    "\n",
    "                \n",
    "#             #sub_msa = sub_hog_leaf_list\n",
    "            \n",
    "#         else:   # the child node is an internal node, subHOGs are inferred till now during traversing.\n",
    "            \n",
    "#             print(\"sub msa for internal node\", node_child.name,\"is read from dic.\")\n",
    "#             #if node_child.name in dic_sub_msas:\n",
    "#                 #sub_msa  = dic_sub_msas[node_child.name]\n",
    "#                 # subHOG_childeren ???\n",
    "#             if node_child.name in dic_sub_hogs:\n",
    "#                 sub_hogs_child  = dic_sub_hogs[node_child.name]\n",
    "                \n",
    "#                 subHOG_childeren += sub_hogs_child\n",
    "                \n",
    "#             else:\n",
    "#                 print(\"error 131, no sub msa for the internal node \",node_child.name, node_child)\n",
    "#                 assert 2==1 \n",
    "                \n",
    "                \n",
    "#         #sub_msa_list_lowerLevel += sub_msa\n",
    "\n",
    "\n",
    "#     if len(sub_msa_list_lowerLevel) <2:\n",
    "#         print(\"**** issue **  \", len(sub_msa_list_lowerLevel),sub_msa_list_lowerLevel)\n",
    "#         #return (-1,-1,-1)\n",
    "    \n",
    "#     print(\"There are\",len(sub_msa_list_lowerLevel),\" subHOGs in the lower level.\")\n",
    "#     #print(\"We want to infer subHOGs at this level,i.e. merge few of them.\")    \n",
    "#     #time.sleep(1)     # shall I wait to have all  msa run finsihed? \n",
    "    \n",
    "#     sub_msa_list_lowerLevel_ready = [hog._msa for hog in sub_msa_list_lowerLevel]\n",
    "#     merged_msa = merge_msa(sub_msa_list_lowerLevel_ready) \n",
    "\n",
    "#     print(\"All subHOGs are merged, merged msa is with length of\",len(merged_msa), len(merged_msa[0]),\".\")\n",
    "\n",
    "#     gene_tree_file =  address_working_folder + \"/gene_trees_test/tree_\"+str(rhogid_num)+\"_\"+str(node_species_tree.name)+\".nwk\"\n",
    "    \n",
    "#     gene_tree_raw = draw_tree(merged_msa, gene_tree_file)\n",
    "#     gene_tree = Tree(gene_tree_raw+\";\", format=0)\n",
    "#     print(\"Gene tree is infered with length of\",len(gene_tree),\".\")\n",
    "\n",
    "#     #gene_tree_i +=1\n",
    "#     R = gene_tree.get_midpoint_outgroup()\n",
    "#     gene_tree.set_outgroup(R)\n",
    "#     #print(\"Midpoint rooting is done for gene tree.\")\n",
    "\n",
    "#     gene_tree = lable_SD_internal_nodes(gene_tree)\n",
    "#     print(\"Overlap speciation is done for internal nodes of gene tree.\")\n",
    "#     print(str(gene_tree.write(format=1))[:-1]+str(gene_tree.name)+\":0;\")\n",
    "#     #print(gene_tree)\n",
    "\n",
    "# #     (assigned_leaves_to_hog, sub_msas_list_this_level) = traverse_geneTree_assign_hog(gene_tree, merged_msa)\n",
    "\n",
    "# #     tree_leaves = [ i.name for i in gene_tree.get_leaves()] \n",
    "# #     if set(tree_leaves)-set(assigned_leaves_to_hog) :\n",
    "# #         print(\"error 234\",assigned_leaves_to_hog, sub_msas_list_this_level)\n",
    "\n",
    "# #     dic_sub_msas[node_species_tree.name] = sub_msas_list_this_level \n",
    "# #     print(\"Number of hog at the taxonomic level\", node_species_tree.name ,\"is \",len(sub_msas_list_this_level),\". The number of proteins per hog is\", [len(i) for i in  sub_msas_list_this_level])    \n",
    "\n",
    "# #     # compare with  subHOG_lowerLevel merge if needed two are from different \n",
    "# #     subHOG_thisLevel =[]\n",
    "# #     for submsa in sub_msas_list_this_level :\n",
    "# #         subHOG_thisLevel.append([seq.id for seq in submsa])\n",
    "# #     #print(\"subHOGs are:\", subHOG_thisLevel)\n",
    "\n",
    "# #     paralog_set_thisLevel = find_paralog_thisLevel(tree_leaves, subHOG_thisLevel)\n",
    "\n",
    "# #     return (subHOG_thisLevel, paralog_set_thisLevel, dic_sub_msas)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4875be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gene_tree should be labeled with S/ D\n",
    "tree_leaves = [ i.name for i in gene_tree.get_leaves()] \n",
    "assigned_leaves_to_hog = []\n",
    "sub_msas_list_this_level = []\n",
    "assigned_lower_level_hogs_id = []\n",
    "lower_level_hogs_id = [subHOG._hogid  for subHOG in subHOG_childeren ]\n",
    "print(lower_level_hogs_id)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for node in gene_tree.traverse(strategy = \"preorder\"): # start from root\n",
    "    #print(\"Leaves assigned to hog are \", assigned_leaves_to_hog)\n",
    "    #print(\"Traversing gene tree. Now at node\", node.name)\n",
    "\n",
    "    if node.is_root() and node.name[0] == \"S\":    \n",
    "        sub_msas_list_this_level = [merged_msa]\n",
    "        assigned_leaves_to_hog = tree_leaves\n",
    "        # we do not need to traverse the gene tree any more \n",
    "        break\n",
    "\n",
    "    if not node.is_leaf() : \n",
    "        node_leaves_name = [ i.name for i in node.get_leaves() ] \n",
    "\n",
    "        # ?? ?? \n",
    "        if node_leaves_name[0] in assigned_leaves_to_hog:\n",
    "            # if one of them is there, since  preorder,  all should be there ???    \n",
    "            # the node are assigned to hogs, we are done. \n",
    "            # it is not needed to check the children of a speciecation\n",
    "            continue  # go to next node\n",
    "\n",
    "        if node.name[0] ==\"S\":\n",
    "            # this is a sub-hog.\n",
    "            print(node)\n",
    "            print(node_leaves_name)\n",
    "            \n",
    "            # find out to which subhog this belongs to \n",
    "            print(\"inter  **\",)\n",
    "            set_lower_level_this_speciation_node = set()\n",
    "            \n",
    "            for node_leave_name in node_leaves_name:\n",
    "                for subHOG_idx in range(len(subHOG_childeren)):\n",
    "                    subHOG = subHOG_childeren[subHOG_idx]\n",
    "                    subHOG_members = subHOG.get_members()\n",
    "                    if node_leave_name in subHOG_members: # subHOG_members.intersection(set(node_leaves_name)) : \n",
    "                        set_lower_level_this_speciation_node |= set([subHOG_idx] ) # [subHOG._hogid]\n",
    "            \n",
    "            \n",
    "            assigned_leaves_to_hog += node_leaves_name\n",
    "            \n",
    "            \n",
    "            sub_hogs_seq = []\n",
    "            \n",
    "            for subHOG_idx in set_lower_level_this_speciation_node:\n",
    "                \n",
    "                sub_hogs_seq += [i for i in subHOG_childeren[subHOG_idx]._msa]\n",
    "              \n",
    "            hog23= HOG(sub_hogs_seq, merged_msa)\n",
    "            \n",
    "        \n",
    "        \n",
    "            #leaves_msa = [i.id for i in merged_msa]\n",
    "            \n",
    "            #idx_species_list = [leaves_msa.index(i) for i in node_leaves_name] \n",
    "            \n",
    "            \n",
    "            # print which should bemerged\n",
    "            # dont merge now\n",
    "            #  we will merge later based on incosnisteny  , based on info   # shared prot\n",
    "            # but we need to merge for small cases to be aable to go upper species \n",
    "            \n",
    " \n",
    "            \n",
    "            \n",
    "            \n",
    "#             #print(\"idx_species_list\",idx_species_list)\n",
    "#             #print(\"node_leaves_name\",node_leaves_name)\n",
    "\n",
    "#             sub_msa_seq_list = [  merged_msa[i]   for i in idx_species_list]  # sub_msas_list_lowerlevel \n",
    "#             sub_msa = run_one_msa(sub_msa_seq_list)\n",
    "#             sub_msas_list_this_level.append(sub_msa)\n",
    "\n",
    "#             if  set(tree_leaves)==set(assigned_leaves_to_hog) :\n",
    "#                 # all leaves are assigned to hogs, we are done. \n",
    "#                 break\n",
    "\n",
    "#     if node.is_leaf() and not node.name in assigned_leaves_to_hog:\n",
    "#         #  singletone leaf, can be a hog. \n",
    "#         assigned_leaves_to_hog.append(node.name)\n",
    "#         #print(\"assigned_leaves_to_hog\",assigned_leaves_to_hog)\n",
    "#         leaves_msa = [i.id for i in merged_msa]\n",
    "#         #print(\"leaves_msa\",leaves_msa)\n",
    "#         idx_species = leaves_msa.index(node.name)\n",
    "#         sub_msa = MultipleSeqAlignment([merged_msa[idx_species]])\n",
    "#         sub_msas_list_this_level.append(sub_msa)\n",
    "\n",
    "\n",
    "\n",
    "print(set_lower_level_this_speciation_node)                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb6769b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acfbc45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06730388",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
