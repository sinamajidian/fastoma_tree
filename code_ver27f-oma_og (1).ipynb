{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d0927039",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python3\n",
    "\n",
    "import numpy as np\n",
    "from sys import argv\n",
    "#import pyoma.browser.db as db\n",
    "import pyoma.browser.models as mod\n",
    "import zoo.wrappers.aligners.mafft as mafft\n",
    "import zoo.wrappers.treebuilders.fasttree as fasttree\n",
    "from Bio import SeqIO\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio import AlignIO\n",
    "from Bio.Align import MultipleSeqAlignment\n",
    "from Bio.Alphabet import IUPAC, SingleLetterAlphabet\n",
    "from Bio.Seq import Seq, UnknownSeq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from collections import defaultdict\n",
    "\n",
    "import pickle\n",
    "    \n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from datetime import datetime\n",
    "\n",
    "import concurrent.futures\n",
    "\n",
    "\n",
    "import ast\n",
    "# #  for development \n",
    "# import matplotlib\n",
    "# matplotlib.use('Agg')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "datasets_address= \"/work/FAC/FBM/DBC/cdessim2/default/smajidi1/fastoma/archive/\"\n",
    "oma_database_address = datasets_address + \"OmaServer.h5\"\n",
    "hog_og_map_address = datasets_address + \"hog_og_map.dic\"\n",
    "omaID_address = datasets_address+\"oma-species.txt\"\n",
    "bird6ID_address = datasets_address+\"info.tsv\"\n",
    "\n",
    "\n",
    "project_folder =\"/work/FAC/FBM/DBC/cdessim2/default/smajidi1/fastoma/v4a/proteome/\" \n",
    "# very small\n",
    "#project_folder = \"/work/FAC/FBM/DBC/cdessim2/default/smajidi1/fastoma/v3a/ST/f4_100S/\" \n",
    "\n",
    "\n",
    "## global variable\n",
    "#project_folder = \"/work/FAC/FBM/DBC/cdessim2/default/smajidi1/fastoma/v3a/A/f7_2kA/\" \n",
    "\n",
    "#project_folder = argv[1]\n",
    "\n",
    "\n",
    "# PANPA.fa  PANPA.hogmap\n",
    "# The species name of query is the name of the file; \n",
    "#  argv[2] \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfe573f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def parse_oma(oma_database_address, hog_og_map_address):\n",
    "    \n",
    "    ############### Parsing OMA db ####################\n",
    "    ###################################################\n",
    "\n",
    "    oma_db = db.Database(oma_database_address)\n",
    "\n",
    "    current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "    print(current_time, \"- OMA data is parsed and its release name is:\", oma_db.get_release_name())\n",
    "    list_speices= [z.uniprot_species_code for z in oma_db.tax.genomes.values()] \n",
    "    current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "    print(current_time,\"- There are\",len(list_speices),\"species in the OMA database.\")\n",
    "\n",
    "    hog_OG_map = []\n",
    "#     file = open(hog_og_map_address, \"r\")\n",
    "#     contents = file.read()\n",
    "#     hog_OG_map = ast.literal_eval(contents)\n",
    "#     file.close()\n",
    "#     current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "#     print(current_time,\"- The hog-og map is read from file with the length of \", len(hog_OG_map))\n",
    "    \n",
    "    \n",
    "    return (oma_db, hog_OG_map, list_speices)\n",
    "\n",
    "\n",
    "def parse_proteome(list_speices):\n",
    "    \n",
    "    ############### Parsing query proteome of species #######\n",
    "    #########################################################\n",
    "\n",
    "    project_files = listdir(project_folder)\n",
    "\n",
    "    query_species_names = []\n",
    "    for file in project_files:\n",
    "        if file.split(\".\")[-1]==\"fa\":\n",
    "            file_name_split = file.split(\".\")[:-1]\n",
    "            query_species_names.append('.'.join(file_name_split))\n",
    "\n",
    "    # we may assert existence of query_species_name+\".fa/hogmap\"\n",
    "    query_prot_records_species = [ ]\n",
    "    for query_species_name in query_species_names:\n",
    "        query_prot_address = project_folder + query_species_name + \".fa\" \n",
    "        query_prot_records = list(SeqIO.parse(query_prot_address, \"fasta\")) \n",
    "        query_prot_records_species.append(query_prot_records)\n",
    "    query_species_num = len(query_species_names)    \n",
    "    current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "    print(current_time,\"- The are\",str(query_species_num),\"species in the project folder.\")\n",
    "\n",
    "    # for development\n",
    "    query_species_num = len(query_species_names)\n",
    "    for species_i in range(query_species_num):\n",
    "        len_prot_record_i = len( query_prot_records_species[species_i] )\n",
    "        species_name_i = query_species_names[species_i]\n",
    "        #print(species_name_i,len_prot_record_i)\n",
    "        if species_name_i in list_speices: \n",
    "            current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "            print(current_time,\"- the species\",species_name_i,\" already exists in the oma database, remove it first\")\n",
    "            exit()\n",
    "\n",
    "    return (query_species_names, query_prot_records_species)\n",
    "\n",
    "\n",
    "\n",
    "# def parse_hogmap_omamer(query_species_names):\n",
    "\n",
    "#     ################### Parsing omamer's output  ########\n",
    "#     #####################################################\n",
    "\n",
    "#     query_prot_names_species = []\n",
    "#     query_hogids_species = []\n",
    "\n",
    "#     for query_species_name in query_species_names:\n",
    "#         omamer_output_address = project_folder + query_species_name + \".hogmap\"     \n",
    "#         omamer_output_file = open(omamer_output_address,'r');\n",
    "\n",
    "#         query_prot_names= []\n",
    "#         query_hogids= []\n",
    "\n",
    "#         for line in omamer_output_file:\n",
    "#             line_strip=line.strip()\n",
    "#             if not line_strip.startswith('qs'):\n",
    "#                 line_split= line_strip.split(\"\\t\")        \n",
    "#                 query_prot_names.append(line_split[0])\n",
    "#                 query_hogids.append(line_split[1])\n",
    "#         #print(\"number of proteins in omamer output for \",query_species_name,\"is\",len(query_hogids)) # ,query_hogids\n",
    "#         query_prot_names_species.append(query_prot_names)\n",
    "#         query_hogids_species.append(query_hogids)    \n",
    "        \n",
    "#     current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "#     print(current_time,\"- There are \",len(query_prot_names_species),\" in project folder.\")\n",
    "#     print(current_time,\"- The first species\",query_prot_names[0],\" contains \",len(query_hogids_species[0]),\" proteins.\")\n",
    "\n",
    "    \n",
    "#     return (query_prot_names_species, query_hogids_species)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def extract_unique_hog_pure(query_species_names,query_hogids_species, query_prot_names_species,query_prot_records_species):\n",
    "    ###### Extracting unique HOG list and corresponding query proteins ########\n",
    "    ###########################################################################\n",
    "\n",
    "    current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "    print(current_time,\"- Extracting proteins mapped only once on a HOG is started\")\n",
    "\n",
    "    query_hogids_filtr_species = []\n",
    "    query_prot_names_filtr_species = []\n",
    "    query_prot_records_filtr_species = []\n",
    "\n",
    "    repeated_hogid_num = 0\n",
    "    \n",
    "    query_species_num = len(query_species_names) \n",
    "    \n",
    "    dic_hogs_list=[]  # a list of dictinaries \n",
    "\n",
    "\n",
    "    for species_i in range(query_species_num):\n",
    "\n",
    "        query_hogids =  query_hogids_species[species_i]\n",
    "        query_prot_names = query_prot_names_species[species_i]\n",
    "        query_prot_records  = query_prot_records_species[species_i]\n",
    "        \n",
    "        dic_hogs = {}\n",
    "        for prot_i in range(len(query_hogids)):\n",
    "            query_hogid      = query_hogids[prot_i]\n",
    "            query_prot_name  = query_prot_names[prot_i]\n",
    "            query_prot_record= query_prot_records[prot_i]\n",
    "            if  query_hogid  not in  dic_hogs:\n",
    "                dic_hogs[query_hogid]=[(query_prot_name,query_prot_record)]\n",
    "            else:\n",
    "                repeated_hogid_num += 1 \n",
    "                dic_hogs[query_hogid].append((query_prot_name,query_prot_record))\n",
    "        dic_hogs_list.append(dic_hogs)\n",
    "\n",
    "        \n",
    "    for dic_hogs in dic_hogs_list: # each species\n",
    "        \n",
    "        query_prot_names_filtr = []\n",
    "        query_prot_records_filtr = []\n",
    "\n",
    "        hogid_list = list(dic_hogs.keys())\n",
    "        for hogid in hogid_list:\n",
    "            list_query_prot = dic_hogs[hogid]\n",
    "            if len(list_query_prot)>1:\n",
    "                del dic_hogs[hogid]\n",
    "        #here dic_hogs is updated and  dic_hogs_list  is also updated.\n",
    "        \n",
    "        #print(len(hogid_list),len(dic_hogs))\n",
    "        #for key, value in d.items():\n",
    "        query_hogids_filtr = []\n",
    "        query_prot_names_filtr = []\n",
    "        query_prot_records_filtr = []        \n",
    "        #query_hogids_filtr=list(dic_hogs.keys())\n",
    "        for hogid, tuple_value  in dic_hogs.items():\n",
    "            query_hogids_filtr.append(hogid)\n",
    "            query_prot_names_filtr.append(tuple_value[0][0])\n",
    "            query_prot_records_filtr.append(tuple_value[0][1])\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        query_hogids_filtr_species.append(query_hogids_filtr)\n",
    "        query_prot_names_filtr_species.append(query_prot_names_filtr)\n",
    "        query_prot_records_filtr_species.append(query_prot_records_filtr)        \n",
    "    \n",
    "    current_time  = datetime.now().strftime(\"%H:%M:%S\")\n",
    "    print(current_time,\"- Extracting proteins mapped only once on a HOG is finished\")\n",
    "    num_all_hogs=np.sum([len(dic_hogs) for dic_hogs in dic_hogs_list])\n",
    "    print(current_time,\"- For \",len(dic_hogs_list),\" species, we keep only\",num_all_hogs,\"HOGs.\")\n",
    "    \n",
    "\n",
    "    return (query_hogids_filtr_species, query_prot_names_filtr_species, query_prot_records_filtr_species )\n",
    "  \n",
    "\n",
    "# def extract_unique_hog(query_species_names,query_hogids_species, query_prot_names_species,query_prot_records_species):\n",
    "#     ###### Extracting unique HOG list and corresponding query proteins ########\n",
    "#     ###########################################################################\n",
    "\n",
    "#     query_hogids_filtr_species = []\n",
    "#     query_prot_names_filtr_species = []\n",
    "#     query_prot_records_filtr_species = []\n",
    "\n",
    "#     repeated_hogid_num = 0\n",
    "    \n",
    "#     query_species_num = len(query_species_names) \n",
    "    \n",
    "#     for species_i in range(query_species_num):\n",
    "#         #print(query_species_names[species_i])\n",
    "\n",
    "#         query_hogids =  query_hogids_species[species_i]\n",
    "#         query_prot_names = query_prot_names_species[species_i]\n",
    "#         query_prot_records  = query_prot_records_species[species_i]\n",
    "\n",
    "\n",
    "\n",
    "#         query_hogids_filtr = []\n",
    "#         query_prot_names_filtr = []\n",
    "#         query_prot_records_filtr = []\n",
    "\n",
    "#         for prot_i in range(len(query_hogids)):\n",
    "\n",
    "#             if not query_hogids[prot_i] in query_hogids_filtr: \n",
    "\n",
    "#                 query_hogids_filtr.append(query_hogids[prot_i])\n",
    "#                 query_prot_names_filtr.append(query_prot_names[prot_i])\n",
    "#                 query_prot_records_filtr.append(query_prot_records[prot_i])\n",
    "#             else:\n",
    "#                 repeated_hogid_num += 1 \n",
    "#                 # for development\n",
    "#                 #print(\"repeated hogid\",query_hogids[prot_i], \" for protein \",query_prot_names[prot_i])\n",
    "#                 # now we keep the first protein query when these are repeated\n",
    "\n",
    "\n",
    "#         query_hogids_filtr_species.append(query_hogids_filtr)\n",
    "#         query_prot_names_filtr_species.append(query_prot_names_filtr)\n",
    "#         query_prot_records_filtr_species.append(query_prot_records_filtr)\n",
    "\n",
    "\n",
    "#         num_query_filtr = len(query_hogids_filtr)\n",
    "#         #print(\"Number of prot queries after filtering is\",num_query_filtr,\"\\n\")\n",
    "\n",
    "    \n",
    "\n",
    "#     return (query_hogids_filtr_species, query_prot_names_filtr_species, query_prot_records_filtr_species )\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c023767",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def gather_OG(query_species_names, query_hogids_filtr_species, query_prot_names_filtr_species, query_prot_records_filtr_species):\n",
    "\n",
    "    ############ Extracting the most frequent OG  ########\n",
    "    #####################################################\n",
    "\n",
    "    #dict (oma_group_nr -> dict(species, [proteins]))\n",
    "    #Og[555] = {homo_erectus: [blabla, blublu], yellow_bird: [P52134], brown_bear: [P2121,B53223]}\n",
    "\n",
    "    OGs_queries = {}\n",
    "\n",
    "    # hog_OG_map = {}\n",
    "\n",
    "    mostFrequent_OG_list_species = []\n",
    "\n",
    "    frq_most_frequent_og_list_all = [] # for development\n",
    "    \n",
    "    query_species_num = len(query_species_names)  \n",
    "    for species_i in  range(query_species_num):\n",
    "\n",
    "        query_species_name = query_species_names[species_i]\n",
    "        #print(\"\\n\",query_species_name)\n",
    "\n",
    "        query_hogids_filtr = query_hogids_filtr_species[species_i]\n",
    "        query_prot_names_filtr = query_prot_names_filtr_species[species_i]\n",
    "        query_prot_records_filtr = query_prot_records_filtr_species[species_i]\n",
    "\n",
    "        mostFrequent_OG_list=[]\n",
    "\n",
    "        num_query_filtr = len(query_hogids_filtr)\n",
    "        for  item_idx in range(num_query_filtr): #\n",
    "\n",
    "            #query_protein = query_prot_names_filtr[item_idx]\n",
    "            seqRecords_query =  query_prot_records_filtr[item_idx]\n",
    "            seqRecords_query_edited = SeqRecord(Seq(str(seqRecords_query.seq)), query_species_name, '', '')\n",
    "            #print(seqRecords_query_edited)\n",
    "\n",
    "            hog_id= query_hogids_filtr[item_idx]\n",
    "\n",
    "            if not hog_id in hog_OG_map:   # Caculitng  most frq OG for the new hog\n",
    "                mostFrequent_OG= -1\n",
    "                hog_OG_map[hog_id]=mostFrequent_OG\n",
    "\n",
    "            else:  # hog_id is in hog_OG_map dic\n",
    "                #print(\"using the hog-og-map\")\n",
    "                mostFrequent_OG = hog_OG_map[hog_id]\n",
    "\n",
    "            if mostFrequent_OG in OGs_queries:\n",
    "                OGs_queries_k = OGs_queries[mostFrequent_OG]\n",
    "\n",
    "                if not query_species_name in OGs_queries_k:\n",
    "                    OGs_queries_k[query_species_name] = seqRecords_query_edited\n",
    "                    OGs_queries[mostFrequent_OG] = OGs_queries_k\n",
    "            else:\n",
    "                OGs_queries[mostFrequent_OG] = {query_species_name: seqRecords_query_edited} # query_protein = query_prot_names_filtr[item_idx]\n",
    "    current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "    print(current_time, \"- Needed HOH-OG map \",len(OGs_queries),\"are extracted from the map file.\") \n",
    "    \n",
    "    return OGs_queries\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f67b4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    \n",
    "def filter_gathered_OG(OGs_queries, query_species_names,keep_og_treshold_species_query):\n",
    "\n",
    "    \n",
    "    current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "    print(current_time, \"- Start filtering OGs of proteme queries with length of \", len(OGs_queries),\"for \",len(query_species_names),\"species.\") \n",
    "       \n",
    "        \n",
    "        \n",
    "    OGs_queries_filtr={}\n",
    "\n",
    "    query_species_og_kept_set= set()\n",
    "\n",
    "    query_species_num_OGs_list=[]\n",
    "    for OG_id, values in OGs_queries.items():\n",
    "        query_species_og= list(values.keys())\n",
    "\n",
    "        query_species_num_OGs_list.append(len(query_species_og)) \n",
    "        if len(query_species_og) > keep_og_treshold_species_query:\n",
    "            OGs_queries_filtr[OG_id]=values\n",
    "            query_species_og_kept_set= query_species_og_kept_set.union(set(query_species_og))\n",
    "\n",
    "\n",
    "    current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "    print(current_time, \"- Finished filetering from \",len(OGs_queries),\", now only\",len(OGs_queries_filtr),\"OGs are remained.\") \n",
    "               \n",
    "\n",
    "\n",
    "    not_included_species =[]\n",
    "    for i in set(query_species_names):\n",
    "        if i not in query_species_og_kept_set:\n",
    "            not_included_species.append(i)\n",
    "\n",
    "    \n",
    "    current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "    print(current_time, \"- These species missed due to the threshold of\",keep_og_treshold_species_query,\":\",not_included_species) \n",
    "               \n",
    "\n",
    "\n",
    "    #query_species_num_OGs_list\n",
    "    # for i in not_included_species:\n",
    "    #     #print(i)\n",
    "    #     for OG_id, values in OGs_queries.items():\n",
    "    #         if i in values:\n",
    "    #             print(values.keys())\n",
    "    # easiet way keep the first one or make list and keep the best\n",
    "    # but better to set trehsold not to misss any species \n",
    "    \n",
    "    return OGs_queries_filtr\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc320ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "def combine_OG_query_filtr(OGs_queries_filtr, oma_db, threshold_least_query_sepecies_in_OG,kept_oma_species_num):\n",
    "    \n",
    "#     ########## Combine proteins of OG with queries ##################\n",
    "#     #################################################################\n",
    "    \n",
    "    current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "    print(current_time, \"- Combining queries with OG started for\",len(OGs_queries_filtr),\"OGs.\") \n",
    "    \n",
    "    species_og_dic={}\n",
    "    \n",
    "    proteins_object_OG_dic={}\n",
    "    for OG_q in OGs_queries_filtr.keys():  # OG found in the query\n",
    "\n",
    "        dic_species_prot = OGs_queries_filtr[OG_q]\n",
    "        if len(dic_species_prot) >threshold_least_query_sepecies_in_OG:\n",
    "            if OG_q != -1:\n",
    "                OG_members = oma_db.oma_group_members(OG_q)\n",
    "                proteins_object_OG = [db.ProteinEntry(oma_db, pr) for pr in OG_members]  # the protein IDs of og members\n",
    "                proteins_object_OG_dic[OG_q]=proteins_object_OG\n",
    "                \n",
    "                species_all_og = [ str(pr.genome.uniprot_species_code) for pr in proteins_object_OG ]\n",
    "\n",
    "                for species in species_all_og:\n",
    "                    if species in species_og_dic:\n",
    "                        #species_og_dic[species].append(OG_q)                        \n",
    "                        species_og_dic[species] +=1 \n",
    "                    else:\n",
    "                        #species_og_dic[species]=[OG_q]\n",
    "                        species_og_dic[species] = 1\n",
    "    \n",
    "    current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "    print(current_time, \"- Number of OMA species per OG is calculated\") \n",
    "                         \n",
    "    species_oma_list=[]\n",
    "    og_num_list = []\n",
    "    for species_oma, og_num in species_og_dic.items():\n",
    "        og_num_list.append(og_num)\n",
    "        species_oma_list.append(species_oma)\n",
    "        \n",
    "    id_species_keep = np.argsort(og_num_list)[-kept_oma_species_num:]\n",
    "    species_oma_kept = [species_oma_list[i] for i in id_species_keep]\n",
    "\n",
    "    current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "    print(current_time, \"- These OMA species are kept\",species_oma_kept) \n",
    "\n",
    "    \n",
    "    seqRecords_OG_queries = []\n",
    "    seqRecords_all_filtr = []\n",
    "    for OG_q in OGs_queries_filtr.keys():  # OG found in the query\n",
    "\n",
    "        dic_species_prot = OGs_queries_filtr[OG_q]\n",
    "        if len(dic_species_prot) >threshold_least_query_sepecies_in_OG:\n",
    "            \n",
    "            seqRecords_query_edited_all = list(dic_species_prot.values())\n",
    "            if OG_q != -1:\n",
    "                proteins_object_OG = proteins_object_OG_dic[OG_q]\n",
    "                 # covnert to biopython objects\n",
    "                seqRecords_OG = []\n",
    "                for pr in proteins_object_OG:\n",
    "                    species_code = str(pr.genome.uniprot_species_code)\n",
    "                    if species_code in species_oma_kept:\n",
    "                        seq_record = SeqRecord(Seq(pr.sequence),species_code,'','') \n",
    "                        seqRecords_OG.append(seq_record)\n",
    "                \n",
    "                seqRecords_OG_queries =seqRecords_OG + seqRecords_query_edited_all\n",
    "                current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "                #print(current_time, \" - Length of OG\",OG_q,\"was\",len(seqRecords_OG),\",now is\",len(seqRecords_OG_queries))\n",
    "                print(current_time, \" - Combining OG\",OG_q,\" with length of \",len(seqRecords_OG),\"\\t with a query \",len(seqRecords_query_edited_all),\" is just finished.\")\n",
    "\n",
    "                seqRecords_all_filtr.append(seqRecords_OG_queries)\n",
    "\n",
    "\n",
    "    current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "    print(\"\\n\", current_time, \"- Combining queries with OG is finished! number of OGs\",len(seqRecords_all_filtr)) # \n",
    "    \n",
    "    \n",
    "    \n",
    "    open_file = open(project_folder+\"_file_combined_OGs_filtr.pkl\", \"wb\")\n",
    "    pickle.dump(seqRecords_all_filtr, open_file)\n",
    "    open_file.close()\n",
    "\n",
    "    current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "    print(\"\\n\", current_time, \"- The variable seqRecords_all_filtr is saved as\", project_folder+\"_file_combined_OGs_filtr.pkl\") # \n",
    "    \n",
    "    return(seqRecords_all_filtr)\n",
    "\n",
    "\n",
    "\n",
    "# def combine_OG_query(OGs_queries, oma_db, threshold_least_query_sepecies_in_OG):\n",
    "    \n",
    "#     ########## Combine proteins of OG with queries ##################\n",
    "#     #################################################################\n",
    "    \n",
    "#     seqRecords_OG_queries = []\n",
    "#     seqRecords_all = []\n",
    "#     for OG_q in OGs_queries.keys():  # OG found in the query\n",
    "\n",
    "#         dic_species_prot = OGs_queries[OG_q]\n",
    "#         if len(dic_species_prot) >threshold_least_query_sepecies_in_OG:\n",
    "\n",
    "#             seqRecords_query_edited_all = []\n",
    "#             for query_species_name,seqRecords_query_edited  in dic_species_prot.items():\n",
    "#                 #print(seqRecords_query_edited)\n",
    "#                 seqRecords_query_edited_all.append(seqRecords_query_edited) \n",
    "\n",
    "\n",
    "#             mostFrequent_OG = OG_q\n",
    "#             if mostFrequent_OG != -1:\n",
    "#                 OG_members = oma_db.oma_group_members(mostFrequent_OG)\n",
    "#                 proteins_object_OG = [db.ProteinEntry(oma_db, pr) for pr in OG_members]  # the protein IDs of og members\n",
    "#                  # covnert to biopython objects\n",
    "#                 seqRecords_OG=[SeqRecord(Seq(pr.sequence),str(pr.genome.uniprot_species_code),'','') for pr in proteins_object_OG]\n",
    "\n",
    "#                 seqRecords_OG_queries =seqRecords_OG + seqRecords_query_edited_all\n",
    "#                 current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "#                 #print(\"length of OG\",mostFrequent_OG,\"was\",len(seqRecords_OG),\",now is\",len(seqRecords_OG_queries))\n",
    "#                 print(current_time, \" - Combining an OG with length of \",len(seqRecords_OG),\"\\t with a query \",len(seqRecords_query_edited_all),\" is just finished.\")\n",
    "\n",
    "#                 seqRecords_all.append(seqRecords_OG_queries)\n",
    "\n",
    "\n",
    "#     current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "#     print(\"\\n\", current_time, \"- Combining queries with OG is finished! number of OGs\",len(seqRecords_all)) # \n",
    "    \n",
    "    \n",
    "    \n",
    "#     open_file = open(project_folder+\"_file_combined_OGs.pkl\", \"wb\")\n",
    "#     pickle.dump(seqRecords_all, open_file)\n",
    "#     open_file.close()\n",
    "\n",
    "    \n",
    "#     return(seqRecords_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "07a84ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_msa_OG(seqRecords_OG_queries):\n",
    "    ############## MSA  ##############\n",
    "    ##################################\n",
    "    #current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "    #print(current_time, \"- working on new OG with length of \",len(seqRecords_OG_queries))\n",
    "\n",
    "    wrapper_mafft = mafft.Mafft(seqRecords_OG_queries,datatype=\"PROTEIN\") \n",
    "    # MAfft error: Alphabet 'U' is unknown. -> add --anysymbol argument needed to define in the sourse code\n",
    "    # workaround sed \"s/U/X/g\"\n",
    "    \n",
    "    wrapper_mafft.options.options['--retree'].set_value(1)\n",
    "\n",
    "\n",
    "    run_mafft = wrapper_mafft() # it's wrapper  storing the result  and time \n",
    "    time_taken_mafft = wrapper_mafft.elapsed_time\n",
    "\n",
    "    result_mafft = wrapper_mafft.result \n",
    "    time_taken_mafft2 = wrapper_mafft.elapsed_time\n",
    "    \n",
    "    current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "    #print(current_time,\"- time elapsed for MSA: \",time_taken_mafft2)\n",
    "    print(current_time,\"- MSA for an OG is just finished: \",time_taken_mafft2)\n",
    "\n",
    "    return(result_mafft)\n",
    "   \n",
    "\n",
    "\n",
    "def run_msa_OG_parallel(seqRecords_all,number_max_workers):\n",
    "        \n",
    "    iterotr_OGs = 0 \n",
    "    \n",
    "    result_mafft_all_species=[]\n",
    "    current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "    print(current_time, \"- Parallel msa is started for \",len(seqRecords_all),\" OGs.\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    with concurrent.futures.ProcessPoolExecutor(max_workers=number_max_workers) as executor: \n",
    "        for seqRecords_OG_queries, output_values in zip(seqRecords_all, executor.map(run_msa_OG, seqRecords_all)):\n",
    "            result_mafft_all_species.append(output_values)\n",
    "\n",
    "            \n",
    "    \n",
    "    open_file = open(project_folder+\"_file_msas.pkl\", \"wb\")\n",
    "    pickle.dump(result_mafft_all_species, open_file)\n",
    "    open_file.close()\n",
    "    \n",
    "    return result_mafft_all_species\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "39595b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def filter_ogs(result_mafft_all_species,ogs_keep_number):\n",
    "\n",
    "    current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "    print(current_time, \"- Filtering MSA started.\")\n",
    "\n",
    "    density_ogs=[]\n",
    "    for msa_og in result_mafft_all_species:\n",
    "\n",
    "        gap_count_og= 0\n",
    "        all_count_og=0\n",
    "        for record in msa_og:\n",
    "            seq=str(record.seq)\n",
    "            gap_count_og += seq.count(\"-\") + seq.count(\"?\") + seq.count(\".\") +seq.count(\"~\")    \n",
    "        #gap_count_ogs.append(gap_count_og)\n",
    "        density_og=gap_count_og/(len(msa_og)*len(msa_og[0]))\n",
    "        density_ogs.append(density_og)\n",
    "        #if density_ogs> treshold_density:\n",
    "    plt.hist(density_ogs,bins=100) # , bins=10\n",
    "    #plt.show()\n",
    "    plt.savefig(project_folder+\"_density_ogs.pdf\")\n",
    "    current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "    print(current_time, \"- The histogram of density ogs is saved.\")\n",
    "    \n",
    "    id_og_keep = np.argsort(density_ogs)[-ogs_keep_number:]\n",
    "    result_mafft_all_species_filtr = [result_mafft_all_species[i] for i in id_og_keep]\n",
    "\n",
    "    current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "    print(current_time, \"- Filtering MSA finished, keeping\",len(result_mafft_all_species_filtr),\"out of\",len(result_mafft_all_species))       \n",
    "    \n",
    "\n",
    "    open_file = open(project_folder+\"_\"+str(ogs_keep_number)+\"_file_msas_filtered.pkl\", \"wb\")\n",
    "    pickle.dump(result_mafft_all_species_filtr, open_file)\n",
    "    open_file.close()\n",
    "\n",
    "        \n",
    "    return result_mafft_all_species_filtr\n",
    "\n",
    "\n",
    "\n",
    "def concatante_alignments(result_mafft_all_species,ogs_keep_number):\n",
    "    ############## Concatante alignments  ##############\n",
    "    ####################################################\n",
    "\n",
    "    #alignments= result_maf2_all\n",
    "    current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "    print(current_time, \"-  MSA concatenation started\")\n",
    "    \n",
    "    \n",
    "    alignments= result_mafft_all_species\n",
    "    current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "    print(current_time, \"- Alignments len\",len(alignments))\n",
    "    #print([len(aln) for aln in alignments ])\n",
    "    #print([len(seq) for aln in alignments for seq in aln])\n",
    "\n",
    "    all_labels_raw = [seq.id for aln in alignments for seq in aln]\n",
    "    all_labels = set(all_labels_raw)\n",
    "    current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "    print(current_time, \"- ids: \",len(all_labels),len(all_labels_raw))\n",
    "    \n",
    "    # Make a dictionary to store info as we go along\n",
    "    # (defaultdict is convenient -- asking for a missing key gives back an empty list)\n",
    "    concat_buf = defaultdict(list)\n",
    "\n",
    "    # Assume all alignments have same alphabet\n",
    "    alphabet = alignments[0]._alphabet\n",
    "\n",
    "    for aln in alignments:\n",
    "        length = aln.get_alignment_length()\n",
    "        #print(\"length\",length)\n",
    "        # check if any labels are missing in the current alignment\n",
    "        these_labels = set(rec.id for rec in aln)\n",
    "        missing = all_labels - these_labels\n",
    "        #print(missing)\n",
    "        # if any are missing, create unknown data of the right length,\n",
    "        # stuff the string representation into the concat_buf dict\n",
    "        for label in missing:\n",
    "            new_seq = UnknownSeq(length, alphabet=alphabet)\n",
    "            concat_buf[label].append(str(new_seq))\n",
    "\n",
    "        # else stuff the string representation into the concat_buf dict\n",
    "        for rec in aln:\n",
    "            concat_buf[rec.id].append(str(rec.seq))\n",
    "\n",
    "    # Stitch all the substrings together using join (most efficient way),\n",
    "    # and build the Biopython data structures Seq, SeqRecord and MultipleSeqAlignment\n",
    "    msa = MultipleSeqAlignment(SeqRecord(Seq(''.join(seq_arr), alphabet=alphabet), id=label)\n",
    "                                for (label, seq_arr) in concat_buf.items())\n",
    "\n",
    "\n",
    "    current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "    print(current_time, \"-  MSA concatenation finished\")\n",
    "\n",
    "    ##########\n",
    "    # print the borders of concatatnion  in nexus format\n",
    "    # http://www.iqtree.org/doc/Advanced-Tutorial\n",
    "    #######\n",
    "    out_name_msa=project_folder+\"_\"+str(ogs_keep_number)+\"_msa_concatanated.txt\"\n",
    "    handle_msa_fasta = open(out_name_msa,\"w\")\n",
    "    SeqIO.write(msa, handle_msa_fasta,\"fasta\")\n",
    "    handle_msa_fasta.close()\n",
    "\n",
    "\n",
    "    # sequences_all=[]\n",
    "    # for spec, sequences in concat_buf.items():\n",
    "    #      sequences_all.append(sequences)\n",
    "    # for i in range(1,100):\n",
    "    #     print(len(sequences_all[0][i]),len(sequences_all[2][i]) ,len(sequences_all[40][i]) )\n",
    "    ## therefore, all of them are with same length of sequences\n",
    "\n",
    "    species_0=list(concat_buf.keys())[0]\n",
    "    sequences =  concat_buf[species_0]\n",
    "    len_all = [len(i) for i in sequences] \n",
    "    borders_in_supermatrix=[]\n",
    "    borders_in_supermatrix.append((1,len_all[0] )) \n",
    "    accumalte = len_all[0]\n",
    "    for i in range(1,100):\n",
    "        borders_in_supermatrix.append((accumalte+1,accumalte+len_all[i]))\n",
    "        accumalte +=len_all[i]\n",
    "\n",
    "    print(len(msa),len(msa[0]),accumalte)\n",
    "    #check it works or not\n",
    "    # for i in range(100):\n",
    "    #     print(borders_in_supermatrix[i][1]-borders_in_supermatrix[i][0]+1,len_all[i])\n",
    "\n",
    "    #borders_in_supermatrix\n",
    "    \n",
    "    # begin sets;\n",
    "    #     charset part1 = 1-100;\n",
    "    #     charset part2 = 101-384;\n",
    "    #     charpartition mine = HKY+G:part1, GTR+I+G:part2;\n",
    "    # end;\n",
    "    borders_out_file_add=project_folder+\"border_out_parition.nex\"\n",
    "    borders_out_file = open(borders_out_file_add,'w')\n",
    "\n",
    "    borders_out_file.write(\"#nexus\"+\"\\n\")\n",
    "    borders_out_file.write(\"begin sets;\"+\"\\n\")\n",
    "\n",
    "    for i, val in enumerate(borders_in_supermatrix):\n",
    "\n",
    "        line=\"    charset part\"+str(i)+\" = \"+str(val[0])+\"-\"+str(val[1])+\";\"\n",
    "        #print(line)\n",
    "        borders_out_file.write(line+'\\n')\n",
    "\n",
    "    borders_out_file.write(\"end;\\n\")\n",
    "    borders_out_file.close()\n",
    "    print(borders_out_file_add)\n",
    "    \n",
    "    \n",
    "    current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "    print(current_time, \"- MSA concatenation has been written in the file\", len(msa),msa.get_alignment_length()) # super matrix size\n",
    "    \n",
    "    \n",
    "    return msa\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6955a359",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def msa_filter_row(msa,tresh_ratio_gap_row,query_species_names,ogs_keep_number):\n",
    "\n",
    "    msa_filtered_row = [] # msa_fltr\n",
    "    ratio_records=[]\n",
    "    for record in msa:\n",
    "        species_name = record.id\n",
    "        seq = record.seq\n",
    "        seqLen = len(record)\n",
    "        \n",
    "        gap_count=seq.count(\"-\") + seq.count(\"?\") + seq.count(\".\") +seq.count(\"~\")\n",
    "                \n",
    "        ratio_record_nongap= 1-gap_count/seqLen\n",
    "        ratio_records.append(round(ratio_record_nongap,3))\n",
    "\n",
    "        if ratio_record_nongap > tresh_ratio_gap_row:\n",
    "            msa_filtered_row.append(record)\n",
    "        elif species_name in query_species_names : \n",
    "            msa_filtered_row.append(record)\n",
    "            current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "            print(current_time, \"- Many row-wise gap for query\",species_name,\"with a ratio of\",ratio_record_nongap) \n",
    "\n",
    "    current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "\n",
    "    print(current_time, \"- Row-wise filtering of MSA is finished.\") \n",
    "    print(current_time, \"- Out of \",len(msa),\"species,\",len(msa_filtered_row),\"species (row of msa) remained.\")\n",
    "\n",
    "    out_name_msa=project_folder+\"_\"+str(ogs_keep_number)+\"_msa_concatanated_filtered_row_\"+str(tresh_ratio_gap_row)+\".txt\"\n",
    "    handle_msa_fasta = open(out_name_msa,\"w\")\n",
    "    SeqIO.write(msa_filtered_row, handle_msa_fasta,\"fasta\")\n",
    "    handle_msa_fasta.close()\n",
    "    \n",
    "    print(current_time, \"- MSA Row-wise filtered stored in file.\") # super matrix size\n",
    "    \n",
    "    \n",
    "    return msa_filtered_row\n",
    "    \n",
    "    \n",
    "\n",
    "def msa_filter_col(msa_filtered_row, tresh_ratio_gap_col,tresh_ratio_gap_row,ogs_keep_number):\n",
    "\n",
    "    ratio_col_all = []\n",
    "\n",
    "    length_record= len(msa_filtered_row[1])\n",
    "    num_records = len(msa_filtered_row)\n",
    "\n",
    "\n",
    "    keep_cols = []\n",
    "    for col_i in range(length_record):  # inspired by https://github.com/andreas-wilm/compbio-utils/blob/master/prune_aln_cols.py \n",
    "\n",
    "        col_values = [record.seq[col_i] for record in msa_filtered_row]\n",
    "\n",
    "        gap_count=col_values.count(\"-\") + col_values.count(\"?\") + col_values.count(\".\") +col_values.count(\"~\")\n",
    "\n",
    "        ratio_col_nongap = 1- gap_count/num_records\n",
    "        ratio_col_all.append(ratio_col_nongap)\n",
    "        if ratio_col_nongap  > tresh_ratio_gap_col:\n",
    "            keep_cols.append(col_i)\n",
    "\n",
    "\n",
    "    plt.hist(ratio_col_all,bins=100) # , bins=10\n",
    "    #plt.show()\n",
    "    plt.savefig(project_folder+\"_ratio_col.pdf\")\n",
    "\n",
    "    current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "    print(current_time, \"- Columns indecis extracted. Out of \", length_record,\"columns,\",len(keep_cols),\"is remained.\") \n",
    "\n",
    "    msa_filtered_row_col = []\n",
    "\n",
    "    for record in msa_filtered_row :\n",
    "        record_seq = str(record.seq)\n",
    "\n",
    "        record_seq_edited  = ''.join([record_seq[i] for i in keep_cols  ])\n",
    "        record_edited= SeqRecord(Seq(record_seq_edited), record.id, '', '')\n",
    "        msa_filtered_row_col.append(record_edited)                         \n",
    "\n",
    "\n",
    "    out_name_msa=project_folder+\"_\"+str(ogs_keep_number)+\"_msa_concatanated_filtered_row_\"+str(tresh_ratio_gap_row)+\"_col_\"+str(tresh_ratio_gap_col)+\".txt\"\n",
    "    handle_msa_fasta = open(out_name_msa,\"w\")\n",
    "    SeqIO.write(msa_filtered_row_col, handle_msa_fasta,\"fasta\")\n",
    "    handle_msa_fasta.close()\n",
    "    \n",
    "    current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "    print(current_time, \"- Column-wise filtering of MSA is finished\",len(msa_filtered_row_col),len(msa_filtered_row_col[0])) \n",
    "       \n",
    "    #msa_filtered_row_col = MultipleSeqAlignment(msa_filtered_row_col)\n",
    "    return msa_filtered_row_col\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e4b586",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def draw_tree(msa):\n",
    "    ############## Tree inference  ###################\n",
    "    ##################################################\n",
    "\n",
    "    wrapper_tree=fasttree.Fasttree(msa,datatype=\"PROTEIN\")\n",
    "    wrapper_tree.options.options['-fastest']    \n",
    "    result_tree1 = wrapper_tree()\n",
    "\n",
    "    time_taken_tree = wrapper_tree.elapsed_time \n",
    "    time_taken_tree\n",
    "\n",
    "    result_tree2 = wrapper_tree.result\n",
    "    tree_nwk=str(result_tree2[\"tree\"])\n",
    "    current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "    print(current_time,\"- \",len(tree_nwk))\n",
    "\n",
    "    out_name_tree=project_folder+\"_tree.txt\"\n",
    "    file1 = open(out_name_tree,\"w\")\n",
    "    file1.write(tree_nwk)\n",
    "    file1.close() \n",
    "    return tree_nwk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41ba97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    #(oma_db, hog_OG_map, list_speices) = parse_oma(oma_database_address, hog_og_map_address)\n",
    "\n",
    "\n",
    "    #(query_species_names, query_prot_records_species) = parse_proteome(list_speices)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90d8f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "    (query_prot_names_species, query_hogids_species) = parse_hogmap_omamer(query_species_names)\n",
    "\n",
    "    \n",
    "    (query_hogids_filtr_species, query_prot_names_filtr_species, query_prot_records_filtr_species) = extract_unique_hog_pure(query_species_names,query_hogids_species, query_prot_names_species,query_prot_records_species) # #extract_unique_hog old function\n",
    "\n",
    "    OGs_queries = gather_OG(query_species_names, query_hogids_filtr_species, query_prot_names_filtr_species, query_prot_records_filtr_species)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e63756d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    keep_og_treshold_species_query =   360 #14 # \n",
    "\n",
    "    OGs_queries_filtr= filter_gathered_OG(OGs_queries, query_species_names,keep_og_treshold_species_query)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024a87a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ebbc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    threshold_least_query_sepecies_in_OG = 320 #  15 # \n",
    "\n",
    "    kept_oma_species_num = 20\n",
    "    \n",
    "    seqRecords_all_filtr = combine_OG_query_filtr(OGs_queries_filtr, oma_db, threshold_least_query_sepecies_in_OG,kept_oma_species_num)\n",
    "    #seqRecords_all_old = combine_OG_query(OGs_queries_filtr, oma_db,threshold_least_query_sepecies_in_OG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6fe9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "    number_max_workers = 1\n",
    "    result_mafft_all_species = run_msa_OG_parallel(seqRecords_all_filtr,number_max_workers)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336ec4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "    ogs_keep_number = 500\n",
    "    result_mafft_all_species_filtr = filter_ogs(result_mafft_all_species,ogs_keep_number)\n",
    "    msa= concatante_alignments(result_mafft_all_species_filtr,ogs_keep_number)\n",
    "\n",
    "\n",
    "\n",
    "    ogs_keep_number = 200\n",
    "    result_mafft_all_species_filtr = filter_ogs(result_mafft_all_species,ogs_keep_number)\n",
    "    msa= concatante_alignments(result_mafft_all_species_filtr,ogs_keep_number)\n",
    "    \n",
    "\n",
    "    ogs_keep_number = 100\n",
    "    result_mafft_all_species_filtr = filter_ogs(result_mafft_all_species,ogs_keep_number)\n",
    "    msa= concatante_alignments(result_mafft_all_species_filtr,ogs_keep_number)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187e4932",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# reading pkl file \n",
    "# open_file = open(project_folder+\"_file_msas2.pkl\", \"rb\")\n",
    "# result_mafft_all_species = pickle.load(open_file)\n",
    "# open_file.close()\n",
    "# print(\"seq read is loaded\", len(seqRecords_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e3199f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4a5e24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4457100",
   "metadata": {},
   "outputs": [],
   "source": [
    "    current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "    print(current_time, \"- Row-wise filtering of MSA is started.\") \n",
    "       \n",
    "    tresh_ratio_gap_row = 0.3\n",
    "    msa_filtered_row = msa_filter_row(msa,tresh_ratio_gap_row,query_species_names,ogs_keep_number)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728c0591",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "    print(current_time, \"- Column-wise filtering of MSA is started.\") \n",
    "    \n",
    "    tresh_ratio_gap_col = 0.3\n",
    "    msa_filtered_row_col=  msa_filter_col(msa_filtered_row, tresh_ratio_gap_col,tresh_ratio_gap_row,ogs_keep_number)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6ac326",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e262c392",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8c4274",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e520ca1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a73ed6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c9a4ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9892bd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345aa103",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e0de505c",
   "metadata": {},
   "source": [
    "# borders of concatantion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb6d5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#     open_file = open(project_folder+\"_file.pkl\", \"rb\")\n",
    "#     seqRecords_all = pickle.load(open_file)\n",
    "#     open_file.close()\n",
    "#     print(\"seq read is loaded\", len(seqRecords_all))\n",
    "#     number_workers  = int(argv[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1302ca9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "ogs_keep_number=100\n",
    "\n",
    "open_file = open(project_folder+\"out_17Jul/_\"+str(ogs_keep_number)+\"_file_msas_filtered.pkl\", \"rb\")\n",
    "result_mafft_all_species_filtr = pickle.load(open_file)\n",
    "\n",
    "#pickle.dump(result_mafft_all_species_filtr, open_file)\n",
    "#open_file.close()\n",
    "# with open('filename.pickle', 'rb') as handle:\n",
    "#     b = pickle.load(handle)\n",
    "\n",
    "\n",
    "\n",
    "result_mafft_all_species= result_mafft_all_species_filtr    \n",
    "alignments= result_mafft_all_species\n",
    "\n",
    "all_labels_raw = [seq.id for aln in alignments for seq in aln]\n",
    "all_labels = set(all_labels_raw)\n",
    "\n",
    "# Make a dictionary to store info as we go along\n",
    "# (defaultdict is convenient -- asking for a missing key gives back an empty list)\n",
    "concat_buf = defaultdict(list)\n",
    "\n",
    "# Assume all alignments have same alphabet\n",
    "alphabet = alignments[0]._alphabet\n",
    "\n",
    "for aln in alignments:\n",
    "    length = aln.get_alignment_length()\n",
    "    #print(\"length\",length)\n",
    "    # check if any labels are missing in the current alignment\n",
    "    these_labels = set(rec.id for rec in aln)\n",
    "    missing = all_labels - these_labels\n",
    "    #print(missing)\n",
    "    # if any are missing, create unknown data of the right length,\n",
    "    # stuff the string representation into the concat_buf dict\n",
    "    for label in missing:\n",
    "        new_seq = UnknownSeq(length, alphabet=alphabet)\n",
    "        concat_buf[label].append(str(new_seq))\n",
    "\n",
    "    # else stuff the string representation into the concat_buf dict\n",
    "    for rec in aln:\n",
    "        concat_buf[rec.id].append(str(rec.seq))\n",
    "\n",
    "# Stitch all the substrings together using join (most efficient way),\n",
    "# and build the Biopython data structures Seq, SeqRecord and MultipleSeqAlignment\n",
    "msa = MultipleSeqAlignment(SeqRecord(Seq(''.join(seq_arr), alphabet=alphabet), id=label)\n",
    "                            for (label, seq_arr) in concat_buf.items())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fbb596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequences_all=[]\n",
    "# for spec, sequences in concat_buf.items():\n",
    "#      sequences_all.append(sequences)\n",
    "# for i in range(1,100):\n",
    "#     print(len(sequences_all[0][i]),len(sequences_all[2][i]) ,len(sequences_all[40][i]) )\n",
    "## therefore, all of them are with same length of sequences\n",
    "\n",
    "species_0=list(concat_buf.keys())[0]\n",
    "sequences =  concat_buf[species_0]\n",
    "len_all = [len(i) for i in sequences] \n",
    "\n",
    "\n",
    "borders_in_supermatrix=[]\n",
    "borders_in_supermatrix.append((1,len_all[0] )) \n",
    "                              \n",
    "accumalte = len_all[0]\n",
    "for i in range(1,100):\n",
    "    borders_in_supermatrix.append((accumalte+1,accumalte+len_all[i]))\n",
    "    accumalte +=len_all[i]\n",
    "\n",
    "print(len(msa),len(msa[0]),accumalte)\n",
    "#check it works or not\n",
    "# for i in range(100):\n",
    "#     print(borders_in_supermatrix[i][1]-borders_in_supermatrix[i][0]+1,len_all[i])\n",
    "\n",
    "#borders_in_supermatrix\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# begin sets;\n",
    "#     charset part1 = 1-100;\n",
    "#     charset part2 = 101-384;\n",
    "#     charpartition mine = HKY+G:part1, GTR+I+G:part2;\n",
    "# end;\n",
    "\n",
    "borders_out_file_add=project_folder+\"out_17Jul/\"+\"border_out_parition.nex\"\n",
    "borders_out_file = open(borders_out_file_add,'w')\n",
    "\n",
    "borders_out_file.write(\"#nexus\"+\"\\n\")\n",
    "borders_out_file.write(\"begin sets;\"+\"\\n\")\n",
    "\n",
    "for i, val in enumerate(borders_in_supermatrix):\n",
    "    \n",
    "    line=\"    charset part\"+str(i+1)+\" = \"+str(val[0])+\"-\"+str(val[1])+\";\"\n",
    "    #print(line)\n",
    "    borders_out_file.write(line+'\\n')\n",
    "\n",
    "borders_out_file.write(\"end;\\n\")\n",
    "borders_out_file.close()\n",
    "print(borders_out_file_add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6bf43a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ebc6ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae7a37f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0cbe5cf2",
   "metadata": {},
   "source": [
    "# OMA OG slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcd6269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# project_folder =\"/work/FAC/FBM/DBC/cdessim2/default/smajidi1/fastoma/v4a/proteome/\" \n",
    "\n",
    "# folder_og= project_folder[:-9]+\"OrthologousGroupsFasta/\"\n",
    "# og_files = listdir(folder_og)\n",
    "\n",
    "# og_file_names = []\n",
    "# for file in og_files:\n",
    "#     if file.split(\".\")[-1]==\"fa\":\n",
    "#         #file_name_split = file.split(\".\")[:-1]\n",
    "#         og_file_names.append(file) #('.'.join(file_name_split))\n",
    "# #og_file_names\n",
    "\n",
    "# og_records = [ ]\n",
    "# for og_file_name in og_file_names:\n",
    "#     query_prot_address = folder_og + og_file_name\n",
    "#     og_record = list(SeqIO.parse(query_prot_address, \"fasta\")) \n",
    "#     og_records.append(og_record)\n",
    "     \n",
    "# len(og_records)\n",
    "\n",
    "# open_file = open(project_folder[:-9]+\"_file_all_ogs.pkl\", \"wb\")\n",
    "# pickle.dump(og_records, open_file)\n",
    "# open_file.close()\n",
    "\n",
    "\n",
    "# len_all=[]\n",
    "# for i in range(len(og_records)):\n",
    "#     #print(len(og_records[i]),og_files[i])\n",
    "#     len_all.append(len(og_records[i]))\n",
    "    \n",
    "# print(sum(len_all)/len(len_all)) \n",
    "# #len_all_log= [np.log10(i) for i in len_all ]\n",
    "# plt.hist(len_all,bins=100) # \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754e0e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open_file = open(project_folder[:-9]+\"_file_all_ogs.pkl\", \"rb\")\n",
    "# og_records= pickle.load(open_file)\n",
    "# open_file.close()\n",
    "# og_records2=og_records\n",
    "# for i in og_records2:\n",
    "#     for j in i:\n",
    "#         j.id=j.id.split('_')[0]\n",
    "        \n",
    "# print(og_records[0][0].id)\n",
    "# print(og_records[0][0].id.split('_'))\n",
    "\n",
    "\n",
    "\n",
    "# og_records_filt=[]\n",
    "# for i in og_records2:\n",
    "#     if len(i)>350:\n",
    "#         og_records_filt.append(i)\n",
    "        \n",
    "        \n",
    "# open_file = open(project_folder[:-9]+\"_file_all_ogs_greater350.pkl\", \"wb\")\n",
    "# pickle.dump(og_records_filt, open_file)\n",
    "# open_file.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6104aa",
   "metadata": {},
   "source": [
    "# from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3785dc20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be79383a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "project_folder =\"/work/FAC/FBM/DBC/cdessim2/default/smajidi1/fastoma/v4a/proteome/\" \n",
    "\n",
    "\n",
    "open_file = open(project_folder[:-9]+\"_file_all_ogs_greater350.pkl\", \"rb\")\n",
    "og_records= pickle.load(open_file)\n",
    "open_file.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "583a6252",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seqRecords_all_filtr=[]\n",
    "for i in og_records:\n",
    "    if len(i)>362:\n",
    "        seqRecords_all_filtr.append(i)\n",
    "len(seqRecords_all_filtr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8538e6e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "363"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "species_all=[]\n",
    "for i in og_records_filt:\n",
    "    for j in i:\n",
    "        species_all.append(j.id)\n",
    "len(set(species_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "93185611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:27:26 - Parallel msa is started for  107  OGs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/FAC/FBM/DBC/cdessim2/default/smajidi1/software/miniconda3/lib/python3.8/subprocess.py:844: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
      "  self.stdout = io.open(c2pread, 'rb', bufsize)\n",
      "/work/FAC/FBM/DBC/cdessim2/default/smajidi1/software/miniconda3/lib/python3.8/subprocess.py:849: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
      "  self.stderr = io.open(errread, 'rb', bufsize)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:27:32 - MSA for an OG is just finished:  5.1447553634643555\n",
      "15:27:39 - MSA for an OG is just finished:  7.935014009475708\n",
      "15:27:48 - MSA for an OG is just finished:  8.459386587142944\n",
      "15:27:56 - MSA for an OG is just finished:  8.087497472763062\n",
      "15:28:13 - MSA for an OG is just finished:  17.25433588027954\n",
      "15:28:16 - MSA for an OG is just finished:  2.6796650886535645\n",
      "15:28:20 - MSA for an OG is just finished:  4.240816354751587\n",
      "15:28:33 - MSA for an OG is just finished:  12.456251859664917\n",
      "15:28:37 - MSA for an OG is just finished:  3.97541880607605\n",
      "15:28:42 - MSA for an OG is just finished:  5.747450113296509\n",
      "15:28:54 - MSA for an OG is just finished:  11.548084020614624\n",
      "15:28:59 - MSA for an OG is just finished:  4.561152696609497\n",
      "15:29:04 - MSA for an OG is just finished:  5.555734872817993\n",
      "15:29:07 - MSA for an OG is just finished:  3.2380287647247314\n",
      "15:29:15 - MSA for an OG is just finished:  8.012350797653198\n",
      "15:29:21 - MSA for an OG is just finished:  5.198085308074951\n",
      "15:29:28 - MSA for an OG is just finished:  6.897313833236694\n",
      "15:29:36 - MSA for an OG is just finished:  8.641218900680542\n",
      "15:29:41 - MSA for an OG is just finished:  4.352579593658447\n",
      "15:29:45 - MSA for an OG is just finished:  4.423980951309204\n",
      "15:29:49 - MSA for an OG is just finished:  3.576350212097168\n",
      "15:29:50 - MSA for an OG is just finished:  1.9332122802734375\n",
      "15:29:55 - MSA for an OG is just finished:  4.609746217727661\n",
      "15:30:07 - MSA for an OG is just finished:  12.011090755462646\n",
      "15:30:14 - MSA for an OG is just finished:  6.520110130310059\n",
      "15:30:20 - MSA for an OG is just finished:  6.837888717651367\n",
      "15:30:32 - MSA for an OG is just finished:  11.867124557495117\n",
      "15:30:39 - MSA for an OG is just finished:  6.478601455688477\n",
      "15:30:43 - MSA for an OG is just finished:  4.066450595855713\n",
      "15:30:50 - MSA for an OG is just finished:  7.509742975234985\n",
      "15:30:56 - MSA for an OG is just finished:  5.930711030960083\n",
      "15:31:03 - MSA for an OG is just finished:  6.244664430618286\n",
      "15:31:06 - MSA for an OG is just finished:  2.978414535522461\n",
      "15:31:15 - MSA for an OG is just finished:  9.354361772537231\n",
      "15:31:20 - MSA for an OG is just finished:  5.100998878479004\n",
      "15:31:25 - MSA for an OG is just finished:  4.496010780334473\n",
      "15:31:26 - MSA for an OG is just finished:  1.5053050518035889\n",
      "15:31:34 - MSA for an OG is just finished:  8.386998414993286\n",
      "15:31:49 - MSA for an OG is just finished:  14.746459245681763\n",
      "15:31:54 - MSA for an OG is just finished:  5.133107662200928\n",
      "15:31:58 - MSA for an OG is just finished:  3.367638349533081\n",
      "15:32:03 - MSA for an OG is just finished:  5.054030656814575\n",
      "15:32:17 - MSA for an OG is just finished:  14.648849725723267\n",
      "15:32:21 - MSA for an OG is just finished:  3.940523386001587\n",
      "15:32:31 - MSA for an OG is just finished:  9.273170709609985\n",
      "15:32:44 - MSA for an OG is just finished:  13.34448766708374\n",
      "15:32:49 - MSA for an OG is just finished:  5.326375246047974\n",
      "15:32:55 - MSA for an OG is just finished:  5.187671422958374\n",
      "15:33:04 - MSA for an OG is just finished:  9.738515853881836\n",
      "15:33:09 - MSA for an OG is just finished:  4.392878532409668\n",
      "15:33:17 - MSA for an OG is just finished:  7.843559265136719\n",
      "15:33:22 - MSA for an OG is just finished:  5.794446706771851\n",
      "15:33:29 - MSA for an OG is just finished:  6.125973701477051\n",
      "15:33:32 - MSA for an OG is just finished:  3.3769690990448\n",
      "15:33:42 - MSA for an OG is just finished:  9.801701068878174\n",
      "15:33:44 - MSA for an OG is just finished:  1.965947151184082\n",
      "15:33:47 - MSA for an OG is just finished:  3.3507437705993652\n",
      "15:33:53 - MSA for an OG is just finished:  5.578868865966797\n",
      "15:33:57 - MSA for an OG is just finished:  4.741371154785156\n",
      "15:34:02 - MSA for an OG is just finished:  4.647496938705444\n",
      "15:34:08 - MSA for an OG is just finished:  5.863877058029175\n",
      "15:34:12 - MSA for an OG is just finished:  4.397100210189819\n",
      "15:34:15 - MSA for an OG is just finished:  3.0354459285736084\n",
      "15:34:18 - MSA for an OG is just finished:  2.8659937381744385\n",
      "15:34:21 - MSA for an OG is just finished:  2.767727851867676\n",
      "15:34:28 - MSA for an OG is just finished:  6.719484090805054\n",
      "15:34:33 - MSA for an OG is just finished:  4.7719457149505615\n",
      "15:34:39 - MSA for an OG is just finished:  6.4629292488098145\n",
      "15:34:42 - MSA for an OG is just finished:  2.897866725921631\n",
      "15:34:47 - MSA for an OG is just finished:  4.611363649368286\n",
      "15:34:48 - MSA for an OG is just finished:  1.5390665531158447\n",
      "15:34:56 - MSA for an OG is just finished:  7.978354215621948\n",
      "15:35:00 - MSA for an OG is just finished:  4.193304061889648\n",
      "15:35:02 - MSA for an OG is just finished:  1.8763718605041504\n",
      "15:35:05 - MSA for an OG is just finished:  3.2503116130828857\n",
      "15:35:15 - MSA for an OG is just finished:  9.97918701171875\n",
      "15:35:31 - MSA for an OG is just finished:  15.121885299682617\n",
      "15:35:45 - MSA for an OG is just finished:  13.978618383407593\n",
      "15:35:47 - MSA for an OG is just finished:  2.693802833557129\n",
      "15:35:55 - MSA for an OG is just finished:  7.438186407089233\n",
      "15:36:09 - MSA for an OG is just finished:  13.856860876083374\n",
      "15:36:10 - MSA for an OG is just finished:  1.742030143737793\n",
      "15:36:16 - MSA for an OG is just finished:  5.716755628585815\n",
      "15:36:19 - MSA for an OG is just finished:  3.1164586544036865\n",
      "15:36:33 - MSA for an OG is just finished:  14.185201644897461\n",
      "15:36:39 - MSA for an OG is just finished:  5.883212566375732\n",
      "15:37:04 - MSA for an OG is just finished:  24.302512645721436\n",
      "15:37:06 - MSA for an OG is just finished:  2.004542589187622\n",
      "15:37:12 - MSA for an OG is just finished:  6.212920904159546\n",
      "15:37:16 - MSA for an OG is just finished:  4.471425294876099\n",
      "15:37:24 - MSA for an OG is just finished:  7.359041929244995\n",
      "15:37:36 - MSA for an OG is just finished:  12.352916479110718\n",
      "15:37:41 - MSA for an OG is just finished:  5.231029033660889\n",
      "15:37:44 - MSA for an OG is just finished:  2.7799935340881348\n",
      "15:37:48 - MSA for an OG is just finished:  3.726606845855713\n",
      "15:38:08 - MSA for an OG is just finished:  20.367735624313354\n",
      "15:38:15 - MSA for an OG is just finished:  6.5082128047943115\n",
      "15:38:20 - MSA for an OG is just finished:  5.05491828918457\n",
      "15:38:23 - MSA for an OG is just finished:  3.687601327896118\n",
      "15:38:29 - MSA for an OG is just finished:  5.8089354038238525\n",
      "15:38:32 - MSA for an OG is just finished:  2.8870649337768555\n",
      "15:38:35 - MSA for an OG is just finished:  3.227508783340454\n",
      "15:38:44 - MSA for an OG is just finished:  8.585886478424072\n",
      "15:38:46 - MSA for an OG is just finished:  2.3197922706604004\n",
      "15:38:49 - MSA for an OG is just finished:  2.6070995330810547\n",
      "15:38:51 - MSA for an OG is just finished:  1.768712043762207\n",
      "15:38:55 - MSA for an OG is just finished:  4.627283334732056\n"
     ]
    }
   ],
   "source": [
    "number_max_workers = 1\n",
    "result_mafft_all_species = run_msa_OG_parallel(seqRecords_all_filtr,number_max_workers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a3f09f68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/work/FAC/FBM/DBC/cdessim2/default/smajidi1/fastoma/v4a/proteome/'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "093eaf76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:32:46 - Filtering MSA started.\n",
      "16:32:47 - The histogram of density ogs is saved.\n",
      "16:32:47 - Filtering MSA finished, keeping 100 out of 107\n",
      "16:32:47 -  MSA concatenation started\n",
      "16:32:47 - Alignments len 100\n",
      "16:32:47 - ids:  363 36300\n",
      "16:32:47 -  MSA concatenation finished\n",
      "363 39303 39303\n",
      "/work/FAC/FBM/DBC/cdessim2/default/smajidi1/fastoma/v4a/proteome/border_out_parition.nex\n",
      "16:32:47 - MSA concatenation has been written in the file 363 39303\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ogs_keep_number = 100\n",
    "result_mafft_all_species_filtr = filter_ogs(result_mafft_all_species,ogs_keep_number)\n",
    "msa= concatante_alignments(result_mafft_all_species_filtr,ogs_keep_number)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cc20fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
